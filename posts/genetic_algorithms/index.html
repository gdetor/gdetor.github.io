<!doctype html>







<html
  class="not-ready lg:text-base"
  style="--bg:#faf8f1"
  lang="en-us"
  dir="ltr"
><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta
    name="viewport"
    content="width=device-width, initial-scale=1, shrink-to-fit=no"
  />

  
  <title>Genetic Algorithms &amp; Island Models - GID</title>

  
  <meta name="theme-color" />

  <meta name="description" content="
In this post, we explore genetic algorithms (GAs) and the so-called
island model (IM). GAs and the IM are optimization methods used to
maximize or minimize a cost function.
What is Optimization?
Let&rsquo;s see an example of an optimization problem we all face every day. Let&rsquo;s
assume you&rsquo;d like to go and grab a couple of coffee from your favorite coffee
shop. Typically, you ask Google to find the fastest way to the store from your
current location. But let&rsquo;s forget about technology for now." />
  <meta name="author" content="Georgios Is. Detorakis" /><link rel="preload stylesheet" as="style" href="https://gdetor.github.io/main.min.css" />

  
  <link rel="preload" as="image" href="https://gdetor.github.io/theme.png" />

  <link rel="preload" as="image" href="https://avatars.githubusercontent.com/u/7115299?v=4" />

  <link rel="preload" as="image" href="https://gdetor.github.io/github.svg" /><link rel="preload" as="image" href="https://gdetor.github.io/linkedin.svg" />

  <script
    defer
    src="https://gdetor.github.io/highlight.min.js"
    onload="hljs.initHighlightingOnLoad();"
  ></script><link
  rel="stylesheet"
  href="https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/katex.min.css"
  integrity="sha384-3UiQGuEI4TTMaFmGIZumfRPtfKQ3trwQE2JgosJxCnGmQpL/lJdjpcHkaaFwHlcI"
  crossorigin="anonymous"
/>
<script
  defer
  src="https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/katex.min.js"
  integrity="sha384-G0zcxDFp5LWZtDuRMnBkk3EphCK1lhEf4UEyEM693ka574TZGwo4IWwS6QLzM/2t"
  crossorigin="anonymous"
></script>
<script
  defer
  src="https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/contrib/auto-render.min.js"
  integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05"
  crossorigin="anonymous"
></script><script>
  document.addEventListener('DOMContentLoaded', () =>
    renderMathInElement(document.body, {
      
      
      delimiters: [
        { left: '$$', right: '$$', display: true },
        { left: '$', right: '$', display: false },
      ],
      
      throwOnError: false,
    }),
  );
</script>


  
  <link
    rel="icon"
    href="https://gdetor.github.io/icons/favicon.ico"
  />
  <link
    rel="apple-touch-icon"
    href="https://gdetor.github.io/apple-touch-icon.png"
  />

  <meta name="generator" content="Hugo 0.147.2">
  <meta itemprop="name" content="Genetic Algorithms & Island Models">
  <meta itemprop="description" content="Genetic algorithms (GAs) are a family of optimization algorithms that can solve constrained and unconstrained optimization problems by mimicking biological evolution. In this post, we introduce the fundamental concepts of GAs and the Island Model, an extension of GAs.">
  <meta itemprop="datePublished" content="2022-04-28T00:00:00+00:00">
  <meta itemprop="dateModified" content="2022-04-28T00:00:00+00:00">
  <meta itemprop="wordCount" content="3401">
  <meta itemprop="keywords" content="Genetic Algorithms,GAIM,Island Model,Optimization"><meta property="og:url" content="https://gdetor.github.io/posts/genetic_algorithms/">
  <meta property="og:site_name" content="GID">
  <meta property="og:title" content="Genetic Algorithms & Island Models">
  <meta property="og:description" content="Genetic algorithms (GAs) are a family of optimization algorithms that can solve constrained and unconstrained optimization problems by mimicking biological evolution. In this post, we introduce the fundamental concepts of GAs and the Island Model, an extension of GAs.">
  <meta property="og:locale" content="en_us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2022-04-28T00:00:00+00:00">
    <meta property="article:modified_time" content="2022-04-28T00:00:00+00:00">
    <meta property="article:tag" content="Genetic Algorithms">
    <meta property="article:tag" content="GAIM">
    <meta property="article:tag" content="Island Model">
    <meta property="article:tag" content="Optimization">

  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Genetic Algorithms & Island Models">
  <meta name="twitter:description" content="Genetic algorithms (GAs) are a family of optimization algorithms that can solve constrained and unconstrained optimization problems by mimicking biological evolution. In this post, we introduce the fundamental concepts of GAs and the Island Model, an extension of GAs.">

  <link rel="canonical" href="https://gdetor.github.io/posts/genetic_algorithms/" />
</head>
<body
    class="bg-(--bg) text-black antialiased duration-200 ease-out [-webkit-tap-highlight-color:transparent] dark:text-white"
  ><header
  class="mx-auto flex h-[4.5rem] max-w-(--w) px-8 whitespace-nowrap lg:justify-center"
>
  <div class="relative z-50 flex items-center ltr:mr-auto rtl:ml-auto">
    <a
      class="-translate-y-[1px] text-2xl font-medium"
      href="https://gdetor.github.io/"
      >GID</a
    >
    <div
      class="btn-dark text-[0px] ltr:ml-4 rtl:mr-4 h-6 w-6 shrink-0 cursor-pointer [background:url(./theme.png)_left_center/_auto_theme('spacing.6')_no-repeat] [transition:_background-position_0.4s_steps(5)] dark:[background-position:right]"
      role="button"
      aria-label="Dark"
    ></div>
  </div>

  <div
    class="btn-menu relative z-50 flex h-[4.5rem] w-[5rem] shrink-0 cursor-pointer flex-col items-center justify-center gap-2.5 lg:hidden ltr:-mr-8 rtl:-ml-8"
    role="button"
    aria-label="Menu"
  ></div>

  <script>
    
    const htmlClass = document.documentElement.classList;
    setTimeout(() => {
      htmlClass.remove('not-ready');
    }, 10);

    
    const btnMenu = document.querySelector('.btn-menu');
    btnMenu.addEventListener('click', () => {
      htmlClass.toggle('open');
    });

    
    const metaTheme = document.querySelector('meta[name="theme-color"]');
    const lightBg = '#faf8f1'.replace(/"/g, '');
    const setDark = (isDark) => {
      metaTheme.setAttribute('content', isDark ? '#000' : lightBg);
      htmlClass[isDark ? 'add' : 'remove']('dark');
      localStorage.setItem('dark', isDark);
    };

    
    const darkScheme = window.matchMedia('(prefers-color-scheme: dark)');
    if (htmlClass.contains('dark')) {
      setDark(true);
    } else {
      const darkVal = localStorage.getItem('dark');
      setDark(darkVal ? darkVal === 'true' : darkScheme.matches);
    }

    
    darkScheme.addEventListener('change', (event) => {
      setDark(event.matches);
    });

    
    const btnDark = document.querySelector('.btn-dark');
    btnDark.addEventListener('click', () => {
      setDark(localStorage.getItem('dark') !== 'true');
    });
  </script>

  <div
    class="nav-wrapper fixed inset-x-0 top-full z-40 flex h-full flex-col justify-center bg-(--bg) pb-16 duration-200 select-none lg:static lg:h-auto lg:flex-row lg:bg-transparent! lg:pb-0 lg:transition-none"
  ><nav
      class="lg:ml-12 lg:flex lg:flex-row lg:items-center lg:space-x-10 rtl:space-x-reverse"
    ><a
        class="block text-center text-xl leading-[5rem] lg:text-base lg:font-normal"
        href="/about/"
        >About</a
      ><a
        class="block text-center text-xl leading-[5rem] lg:text-base lg:font-normal"
        href="/research/"
        >Research</a
      ><a
        class="block text-center text-xl leading-[5rem] lg:text-base lg:font-normal"
        href="/software/"
        >Software</a
      ><a
        class="block text-center text-xl leading-[5rem] lg:text-base lg:font-normal"
        href="/publications/"
        >Publications</a
      ><a
        class="block text-center text-xl leading-[5rem] lg:text-base lg:font-normal"
        href="/artwork/"
        >Artwork</a
      ></nav><nav
      class="mt-12 flex justify-center space-x-10 lg:mt-0 lg:items-center ltr:lg:ml-14 rtl:space-x-reverse rtl:lg:mr-14 dark:invert"
    >
      <a
        class="h-7 w-7 text-[0px] [background:var(--url)_center_center/cover_no-repeat] lg:h-6 lg:w-6"
        style="--url: url(./github.svg)"
        href="https://github.com/gdetor"
        target="_blank"
        rel="me"
      >github</a>
      <a
        class="h-7 w-7 text-[0px] [background:var(--url)_center_center/cover_no-repeat] lg:h-6 lg:w-6"
        style="--url: url(./linkedin.svg)"
        href="https://linkedin.com/in/georgiosdetorakis"
        target="_blank"
        rel="me"
      >linkedin</a>
    </nav>
  </div>
</header>
<main
      class="prose prose-neutral dark:prose-invert relative mx-auto min-h-[calc(100vh-9rem)] max-w-(--w) px-8 pt-14 pb-16"
    ><article>
  <header class="mb-14">
    <h1 class="my-0! pb-2.5">Genetic Algorithms &amp; Island Models</h1><div class="text-xs antialiased opacity-60"><time>Apr 28, 2022</time><span class="mx-1">&middot;</span>
      <span>Georgios Is. Detorakis</span>
      <span class="mx-1">&middot;</span>
      <span>16&nbsp minutes read &nbsp / &nbsp3401&nbsp words</span>
    </div></header>

  <section><div style="text-align: justify;">
<p>In this post, we explore genetic algorithms (GAs) and the so-called
island model (IM). GAs and the IM are optimization methods used to
maximize or minimize a cost function.</p>
<h2 id="what-is-optimization">What is Optimization?</h2>
<p>Let&rsquo;s see an example of an optimization problem we all face every day. Let&rsquo;s
assume you&rsquo;d like to go and grab a couple of coffee from your favorite coffee
shop. Typically, you ask Google to find the fastest way to the store from your
current location. But let&rsquo;s forget about technology for now.</p>
<p>You only have a map. Yes, a paper map! They are still around! You first try to
find the shortest paths from your current location to the coffee shop. If
you&rsquo;re a scrooge, you will define the &ldquo;optimal path&rdquo; as &ldquo;the path I consume the
least fuel.&rdquo;</p>
<p>An optimization problem is a search for the &ldquo;best&rdquo; set of parameters, where
&ldquo;best&rdquo; is defined as the minimum or maximum of some cost function of interest.
Here, that function is our fuel consumption. However, we could have also
designated it to be the distance from start to finish.</p>
<p>Mathematically speaking the problem of a minimization can be formulated as
follows [1]:
Given a function $f:A\subseteq \mathbb{R} \rightarrow \mathbb{R}$ we are
searching for an element $ {\bf x}^* $ such that
$$ f({\bf x}^*) \leq f({\bf x}) $$</p>
<p>for all $ {\bf x} \in A $. Similarly, a maximization would be the search for
a ${\bf x}^* $ such that
$$ f({\bf x}^*) \geq f({\bf x}) $$
for all $ {\bf x} \in A $.</p>
<p>In both cases, we are searching for a global optimum (either a global minimum
or a global maximum). However, it is not always possible to find a global
optimum point in real-life cases. Instead, we can settle for a local minimum or
maximum. For example, that&rsquo;s the compromise we often make when training neural
networks with backpropagation [2].</p>
<p>Figure 1A shows the global minimum of the cost function, $f(x)=x^2$, with a
magenta color. Figure 1B displays what is known as the Rastrigin function in
one dimension. It is evident that this function has multiple local minima
(<em>e.g.,</em>, magenta disc)  and maxima (green disc) as well as one global minimum
at $(0, 0)$ (black disc).</p>
<figure><img src="/images/fun_extremes.png"
    alt="Figure 1. Global and local extremes for (A) $f(x)=x^2$, where the magenta disc indicates the global minimum at $(0, 0)$. (B) For Rastrigin $f(x) = 10 &#43; x^2-10\cos(2\pi x)$, there is a global mimimum at $(0, 0)$ and many local mimima and maxima (for instance see the magenta and green discs, respectively)."><figcaption>
      <p>Figure 1. Global and local extremes for (A) $f(x)=x^2$, where the magenta disc indicates the global minimum at $(0, 0)$. (B) For Rastrigin $f(x) = 10 + x^2-10\cos(2\pi x)$, there is a global mimimum at $(0, 0)$ and many local mimima and maxima (for instance see the magenta and green discs, respectively).</p>
    </figcaption>
</figure>
<p>Sometimes, it&rsquo;s easier to solve a minimization problem from a computational
standpoint. In that case, we would minimize the function $ -f $.</p>
<h2 id="what-is-a-genetic-algorithm">What is a Genetic Algorithm?</h2>
<p>A genetic algorithm is an optimization method that mimics evolution to optimize
a cost function. The entire set of the cost function parameters is called the
genome. Each parameter consists of a gene. Because GA mimics how evolution
works, they require a population of individuals. Each individual is nothing
more than a randomly initialized genome. Any GA starts optimizing a cost
function after initializing a population of genomes (individuals).</p>
<p>In most GA implementations, an individual is a a data structure that holds a
genome (vector of bits, integers, floats, etc.), the corresponding cost to its
genome, a unique ID, a flag indicating whether the current individual is about
to mate (after a selection process), and other relevant information that the
developer deems necessary.</p>
<p>When the GA optimizes a cost function, it usually applies three basic operators:</p>
<ul>
<li>
<p><strong>Selection</strong> This operator selects two individuals from a population
(<em>i.e.,</em> a set of many individuals) to mate and eventually procreate. The
selected individuals are called parents. Some selection operators
are k-tournament, roulette-wheel, random, etc.</p>
</li>
<li>
<p><strong>Crossover</strong> This operator mises the genomes of the selected parents. A
crossover operator will combine a part of the first parent&rsquo;s genome with a
part of the second parent&rsquo;s genome. Some crossover operators are one-point
crossover, two-points crossover, random, etc.</p>
</li>
<li>
<p><strong>Mutation</strong> Finally, the potential offspring&rsquo;s (or child&rsquo;s) genome is
subject to a mutation, which will further change the offspring&rsquo;s genome.
Some of the most used mutation operators are delta, random, etc.</p>
</li>
</ul>
<p>Typically, a GA will repeat every generation&rsquo;s operations mentioned above
(another fancy term for iteration). At every iteration, potential offspring
will replace their parents. Usually, the best-performing offspring will replace
the most poor-performing parents in terms of fitness. We call that kind of
replacement &ldquo;elite&rdquo; replacement. Another idea of replacing the parents is
randomly choosing some of the parents and replacing them.</p>
<p>When the GA exhausts the predefined number of generations, the algorithm
terminates. We can evaluate its performance by inspecting the average fitness
(the average cost function value over all the individuals) or the best-so-far
fitness (BSF). Figure 2A shows a typical example of average fitness and 2B a
BSF. Upon the algorithm&rsquo;s termination, the individual with the best fitness
function provides the genome (set of parameters) optimizes the cost function
[3].</p>
<h2 id="how-a-genetic-algorithm-works">How a Genetic Algorithm works?</h2>
<p>Let&rsquo;s use an example to try to understand how GAs work.</p>
<h3 id="example">Example</h3>
<p>Let&rsquo;s try to solve the XOR problem using a feed-forward neural network.  The
XOR (exclusive OR) is a binary operator that returns true if and only if the
operands are different. This means that if $ X = 1 $ (or $ X = 0 $) and $ Y = 0
$ (or $ Y = 1 $) then $ X \oplus Y = 1 $ (same when ). If both $ X $ and $ Y $
are zeros or ones, then $ X \oplus Y = 0 $.</p>
<figure><img src="/images/xor_net.png"
    alt="Figure 2. XOR neural networ."><figcaption>
      <p>Figure 2. XOR neural networ.</p>
    </figcaption>
</figure>
<p>Our neural network will consist of two input units (since the XOR operator is a
binary one), two hidden units, and one output unit. Please see <a href="https://dev.to/jbahire/demystifying-the-xor-problem-1blk">here</a> for more details on why we choose such an architecture.
Figure 2 shows the neural network we are about to use.  Let&rsquo;s optimize this
neural network that will serve as an XOR operator. To facilitate the demonstration,
let&rsquo;s split the process into four steps:</p>
<ol>
<li>
<p>Define the cost function and the size of our genome.
Since the input to the XOR function is two-dimensional, we have a
genome of size two. Regarding the cost function, we first define an
error term as
$$ \epsilon = | y_{\text{target} - y_{\text{pred}}} | $$
where $ y_{\text{target}} $ is the true value that the XOR function returns
and $x_{\text{pred}}$ is the value of our network&rsquo;s output. Since we have four
pairs of inputs $ (0, 1), (1, 0), (1, 1), (0, 0) $, and four real outputs
$1, 1, 0, 0$, respectively, we define the cost function as:
$$ f({\bf x}) = \sum_{i=1}^{4} \epsilon_i $$
Ideally, we expect the cost function to be zero to get our
optimal solution. That&rsquo;s the case in Figure 2, where we see the best-so-far
fitness and the average fitness.</p>
</li>
<li>
<p>Once we have defined the cost function (that&rsquo;s always the most challenging
part), we determine the number of genes per individual, which is $9$ in
this case. The neural network has the two input units connected via a $ 2
\times 2 $ matrix with the two hidden units. Next, the hidden units
connect via a $ 2\times 1 $ matrix to the output unit. Moreover, the
hidden and output units have a bias term (3 bias terms in total).
Therefore, the entire network has nine parameters (six weights and three
bias terms) we have to optimize. So, we initialize the neural network with
small random weights, define the number of individuals (population size)
to be $ 20 $, and define the size of the genome to be $ 9 $. Remember,
this is the number of cost function parameters to optimize. We set the
number of generations to $ 5000 $,  the number of offspring to $ 10 $, and
the replacement size to $ 5 $, which means $ 5 $ parents will be replaced
by $ 5 $ offsprings.</p>
</li>
<li>
<p>We need to decide what operators we will use for our GA.
In this particular example, we use a k-tournament selection,
a one-point crossover, and a delta mutation operator.</p>
<ul>
<li><strong>k-tournament selection</strong> This operator will randomly choose
$ k $ individuals from the population. It will, then, choose the best
individual, based on the fitness from the tournament with probability
$ p $, choose the second-best individual with probability $ p(1-p) $,
the third-best with probability $ p(1-p)^2 $, etc.</li>
<li><strong>One-point crossover</strong> will take the genes of two parents as input,
it will randomly pick a number from zero to the size of genes, and it
will cut the parents&rsquo; genes at that point. Then it will swap the
sliced genes between the two parents, and thus the offspring will carry
genetic information from both parents.</li>
<li><strong>Delta mutation</strong> operator will draw uniformly a number from the
interval $ [0, 1] $ for each gene in an individual&rsquo;s genome. If that
number is greater than a probability $ p $ (usually $ p = \frac{1}{2} $).
A predefined increment will increase the value of the gene.</li>
</ul>
</li>
<li>
<p>Finally, we set our Optimization in motion. The GA will first evaluate
the cost function of each individual. It will sort the individuals based
on their fitness values. To this end, we feed the XOR input to the neural
network, and we collect the output $ y_{\text{pred}} $. Then we use the
output to compute the cost function value for that individual. The next step
for our GA is to choose two parents based on the k-tournament selection. The
genome of the two selected parents will be crossed over using the
one-point operator. That will give rise to a new genome, a child or
offspring. The offspring&rsquo;s genome will undergo a mutation based on the
delta operator. Finally, the GA will add the offspring to a list.  The
selection, crossover, and mutation processes continue until the number
of offspring have been exhausted. Then, the best performing offspring
will replace the poorest-performing (maximum cost function value)
parents (elite replacement). And the entire process repeats for $ 4999$
more generations.</p>
</li>
</ol>
<p>After the convergence of the process described in step $ 4 $, the Optimization
of the XOR fitness terminates, and we can inspect the results. Figure 3 shows
the best-so-far fitness (BSF) and the average fitness, respectively. The first
observation is that the cost function value indeed converges to zero. Thus, our
GA&rsquo;s best genome is optimal, and our neural network solves the XOR problem. The
second observation is that we could have used only $500$ generations for this
particular instance. The difficulty of the problem at hand usually determines
the number of generations and the initial values of the genome.</p>
<figure><img src="/images/bsf_avg_fit.png"
    alt="Figure 3. BSF and average fitness for the optimization of the XOR fitness function."><figcaption>
      <p>Figure 3. BSF and average fitness for the optimization of the XOR fitness function.</p>
    </figcaption>
</figure>
<p>Bellow, you can find the source code of the Python script we used to optimize
the XOR problem. As you can see, we combine Pytorch and PyGAIM to build
a neural network and optimize the weights and the biases.</p>
<p>The first snippet shows what packages we need to import, the class of the
neural network, and a function that we will use to measure the accuracy
of our optimization process.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py3" data-lang="py3"><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1</span><span><span style="color:#f92672">import</span> sys
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2</span><span><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3</span><span><span style="color:#f92672">import</span> matplotlib.pylab <span style="color:#66d9ef">as</span> plt
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4</span><span><span style="color:#f92672">from</span> random <span style="color:#f92672">import</span> shuffle
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5</span><span>
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6</span><span><span style="color:#f92672">import</span> torch
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7</span><span><span style="color:#f92672">from</span> torch <span style="color:#f92672">import</span> nn
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8</span><span>
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9</span><span>sys<span style="color:#f92672">.</span>path<span style="color:#f92672">.</span>append(<span style="color:#e6db74">&#34;/home/gdetorak/packages/gaim/pygaim&#34;</span>)
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10</span><span><span style="color:#f92672">from</span> pygaim <span style="color:#f92672">import</span> GAOptimize, c2numpy
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11</span><span>
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12</span><span>
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13</span><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">XOR_NET</span>(nn<span style="color:#f92672">.</span>Module):
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14</span><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">__init__</span>(self):
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15</span><span>        super(XOR_NET, self)<span style="color:#f92672">.</span><span style="color:#a6e22e">__init__</span>()
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16</span><span>
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17</span><span>        self<span style="color:#f92672">.</span>fc1 <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Linear(<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">2</span>)
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">18</span><span>        self<span style="color:#f92672">.</span>fc2 <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Linear(<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">19</span><span>        self<span style="color:#f92672">.</span>sigmoid <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Sigmoid()
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">20</span><span>
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">21</span><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, x):
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">22</span><span>        out <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>sigmoid(self<span style="color:#f92672">.</span>fc1(x))
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">23</span><span>        out <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>fc2(out)
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">24</span><span>        <span style="color:#66d9ef">return</span> out
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">25</span><span>
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">26</span><span><span style="color:#75715e"># Instantiate the XOR_NET class</span>
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">27</span><span>net <span style="color:#f92672">=</span> XOR_NET()
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">28</span><span>
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">29</span><span><span style="color:#75715e"># src: Input XOR</span>
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">30</span><span><span style="color:#75715e"># tgt: Output XOR</span>
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">31</span><span>src <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array([[<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>], [<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">0</span>], [<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>], [<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>]], <span style="color:#e6db74">&#39;f&#39;</span>)
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">32</span><span>dst <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array([[<span style="color:#ae81ff">1</span>], [<span style="color:#ae81ff">1</span>], [<span style="color:#ae81ff">0</span>], [<span style="color:#ae81ff">0</span>]], <span style="color:#e6db74">&#39;f&#39;</span>)
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">33</span><span>index <span style="color:#f92672">=</span> [<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">3</span>]
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">34</span><span>
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">35</span><span>
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">36</span><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">accuracy</span>(genome):
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">37</span><span>    <span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">38</span><span><span style="color:#e6db74">    Measures the accuracy of the XOR_NET. Runs over 100 times
</span></span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">39</span><span><span style="color:#e6db74">    and compares the network output against the target pattern
</span></span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">40</span><span><span style="color:#e6db74">    each time.      
</span></span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">41</span><span><span style="color:#e6db74">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">42</span><span>    <span style="color:#75715e"># Assign genomes to network weights</span>
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">43</span><span>    w1 <span style="color:#f92672">=</span> genome[:<span style="color:#ae81ff">4</span>]
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">44</span><span>    b1 <span style="color:#f92672">=</span> genome[<span style="color:#ae81ff">4</span>:<span style="color:#ae81ff">6</span>]
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">45</span><span>    w2 <span style="color:#f92672">=</span> genome[<span style="color:#ae81ff">6</span>:<span style="color:#ae81ff">8</span>]
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">46</span><span>    b2 <span style="color:#f92672">=</span> genome[<span style="color:#ae81ff">8</span>:]
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">47</span><span>
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">48</span><span>    net<span style="color:#f92672">.</span>fc1<span style="color:#f92672">.</span>weight<span style="color:#f92672">.</span>data <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>FloatTensor(w1)<span style="color:#f92672">.</span>reshape(<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">2</span>)
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">49</span><span>    net<span style="color:#f92672">.</span>fc1<span style="color:#f92672">.</span>bias<span style="color:#f92672">.</span>data <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>FloatTensor(b1)
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">50</span><span>    net<span style="color:#f92672">.</span>fc2<span style="color:#f92672">.</span>weight<span style="color:#f92672">.</span>data <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>FloatTensor(w2)<span style="color:#f92672">.</span>reshape(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">2</span>)
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">51</span><span>    net<span style="color:#f92672">.</span>fc1<span style="color:#f92672">.</span>bias<span style="color:#f92672">.</span>data <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>FloatTensor(b2)
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">52</span><span>
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">53</span><span>    count <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">54</span><span>    <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">100</span>):
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">55</span><span>        idx <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>randint(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">4</span>)
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">56</span><span>        inp <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>FloatTensor(src[idx])
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">57</span><span>        tgt <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>FloatTensor(dst[idx])
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">58</span><span>        y <span style="color:#f92672">=</span> net(inp)
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">59</span><span>        <span style="color:#66d9ef">if</span> np<span style="color:#f92672">.</span>round(y<span style="color:#f92672">.</span>item()) <span style="color:#f92672">==</span> np<span style="color:#f92672">.</span>round(tgt<span style="color:#f92672">.</span>item()):
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">60</span><span>            count <span style="color:#f92672">+=</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">61</span><span>            <span style="color:#75715e"># print(y.item(), tgt.item())</span>
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">62</span><span>    print(<span style="color:#e6db74">&#34;Accuracy: </span><span style="color:#e6db74">%d</span><span style="color:#e6db74"> / 100&#34;</span> <span style="color:#f92672">%</span> count)</span></span></code></pre></div>
<p>The fitness function takes the genome (C array) as input and
returns the negative of fitness value (or loss) since we perform
a minimization. It presents each time all four XOR patterns to
the neural network and computes the loss for each pattern.
Finally, it sums up all four individual losses and returns the
total loss.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py3" data-lang="py3"><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1</span><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">fitness</span>(x, length):
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2</span><span>    <span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3</span><span><span style="color:#e6db74">    Fitness function. Receives the genome (x) from GAIM, passes it through
</span></span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4</span><span><span style="color:#e6db74">    net.forward (Pytorch) and computes the absolute loss. 
</span></span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5</span><span><span style="color:#e6db74">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6</span><span>    x <span style="color:#f92672">=</span> c2numpy(x, length)				<span style="color:#75715e"># Convert C array to Numpy</span>
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7</span><span>    w1 <span style="color:#f92672">=</span> x[:<span style="color:#ae81ff">4</span>]						<span style="color:#75715e"># First layer weights (2x2)</span>
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8</span><span>    b1 <span style="color:#f92672">=</span> x[<span style="color:#ae81ff">4</span>:<span style="color:#ae81ff">6</span>]					<span style="color:#75715e"># First layer bias (2X1)</span>
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9</span><span>    w2 <span style="color:#f92672">=</span> x[<span style="color:#ae81ff">6</span>:<span style="color:#ae81ff">8</span>]					<span style="color:#75715e"># Second layer weights (2x1)</span>
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10</span><span>    b2 <span style="color:#f92672">=</span> x[<span style="color:#ae81ff">8</span>:]						<span style="color:#75715e"># Second layer bias (1x1)</span>
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11</span><span>
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12</span><span>    <span style="color:#75715e"># Assign the new values to network weights	</span>
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13</span><span>    net<span style="color:#f92672">.</span>fc1<span style="color:#f92672">.</span>weight<span style="color:#f92672">.</span>data <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>FloatTensor(w1)<span style="color:#f92672">.</span>reshape(<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">2</span>)
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14</span><span>    net<span style="color:#f92672">.</span>fc1<span style="color:#f92672">.</span>bias<span style="color:#f92672">.</span>data <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>FloatTensor(b1)
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15</span><span>    net<span style="color:#f92672">.</span>fc2<span style="color:#f92672">.</span>weight<span style="color:#f92672">.</span>data <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>FloatTensor(w2)<span style="color:#f92672">.</span>reshape(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">2</span>)
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16</span><span>    net<span style="color:#f92672">.</span>fc1<span style="color:#f92672">.</span>bias<span style="color:#f92672">.</span>data <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>FloatTensor(b2)
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17</span><span>
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">18</span><span>    loss <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.0</span>						
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">19</span><span>    shuffle(index)					<span style="color:#75715e"># shuffle the index</span>
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">20</span><span>    <span style="color:#75715e"># loop over all four patterns in a random order</span>
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">21</span><span>    <span style="color:#66d9ef">for</span> idx <span style="color:#f92672">in</span> index:
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">22</span><span>        inp <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>from_numpy(src[idx])
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">23</span><span>        tgt <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>from_numpy(dst[idx])
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">24</span><span>        y <span style="color:#f92672">=</span> net(inp)
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">25</span><span>        loss <span style="color:#f92672">+=</span> torch<span style="color:#f92672">.</span>abs(y[<span style="color:#ae81ff">0</span>] <span style="color:#f92672">-</span> tgt[<span style="color:#ae81ff">0</span>])
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">26</span><span>    <span style="color:#66d9ef">return</span> float(<span style="color:#f92672">-</span>loss<span style="color:#f92672">.</span>item())			<span style="color:#75715e"># return -loss (minimize)</span></span></span></code></pre></div>
The final snippet provides the code to call the GAOptimize function
of PyGAIM, to plot the results and measure the performance (accuracy)
of the neural network on solving XOR.
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py3" data-lang="py3"><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1</span><span>    genome_size <span style="color:#f92672">=</span> <span style="color:#ae81ff">9</span>
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2</span><span>    ga <span style="color:#f92672">=</span> GAOptimize(fitness,
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3</span><span>                    n_generations<span style="color:#f92672">=</span><span style="color:#ae81ff">1000</span>,
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4</span><span>                    population_size<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>,
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5</span><span>                    genome_size<span style="color:#f92672">=</span>genome_size,
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6</span><span>                    n_offsprings<span style="color:#f92672">=</span><span style="color:#ae81ff">5</span>,
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7</span><span>                    n_replacements<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>,
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8</span><span>                    a<span style="color:#f92672">=</span>[float(<span style="color:#f92672">-</span><span style="color:#ae81ff">10.0</span>) <span style="color:#66d9ef">for</span> _ <span style="color:#f92672">in</span> range(genome_size)],
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9</span><span>                    b<span style="color:#f92672">=</span>[float(<span style="color:#ae81ff">10.0</span>) <span style="color:#66d9ef">for</span> _ <span style="color:#f92672">in</span> range(genome_size)],
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10</span><span>                    mutation_rate<span style="color:#f92672">=</span><span style="color:#ae81ff">0.5</span>,
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11</span><span>                    mutation_var<span style="color:#f92672">=</span><span style="color:#ae81ff">.1</span>)
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12</span><span>    genome, _, _ <span style="color:#f92672">=</span> ga<span style="color:#f92672">.</span>fit()
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13</span><span>    ga<span style="color:#f92672">.</span>plot_()
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14</span><span>    test_weights(genome)
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15</span><span>    plt<span style="color:#f92672">.</span>show()</span></span></code></pre></div>
GAIM [4] is a C++ library for genetic algorithms and the island model.
It implements the most fundamental selection, crossover, and mutation
operators. It also provides an MPI and POSIX threads implementation
of the island model. Finally, it comes with a Python interface 
called PyGAIM that simplifies GA-based optimization problem setup,
and PyGAIM provides a scikit-learn-like interface. 
<p>For more information about GAIM, its source code, and examples,
you can visit its <a href="https://github.com/gdetor/gaim">Github</a> repository.</p>
<h2 id="what-is-an-island-model">What is an Island Model?</h2>
<p>An island model is a computational method that runs multiple instances of GAs
on the same optimization problem in a distributed and parallel fashion. In some
cases, each island (another fancy word for process, thread, or computational
node in a cluster) can run a part of the optimization problem [5].</p>
<p>What is essential in an island model is the periodic exchange of individuals
between islands. According to a predetermined time interval, a migration of a
subpopulation takes place. This circulation of individuals between islands
relies on specific communication protocols and predetermined topologies
(<em>e.g.,</em>  ring topology). In this case, the islands are connected, forming a
ring, meaning the current island (node) connects to the one on its right (or
left).</p>
<p>Figure 4 shows three basic topologies, (A) all-to-all, where every island
connects to all other ones, (B) ring, and (C) star topology, where one island
serves as a communication hub [5, 6, 7].</p>
<figure><img src="/images/island_model.png"
    alt="Figure 4. Island model topologies. (A) all-to-all, (B) ring, (C) star."><figcaption>
      <p>Figure 4. Island model topologies. (A) all-to-all, (B) ring, (C) star.</p>
    </figcaption>
</figure>
<p>Each island begins with a population of $N$ individuals where $$ N =
\frac{K}{M} $$ where $ K $ is the number of all individuals, and $M$ is the
number of islands.
Every island will initialize a GA based on all the parameters and procedures
described earlier. When a time counter exhausts, migration takes place. The IM
algorithm selects a subpopulation on each island via some selection method
(random, elite - the best performing individuals, etc.). The selected genomes
move to the neighboring, connected island or islands. The newly arrived ones
replace local individuals via a replacement method (random, poor - the
worst-performing individuals, etc.). IM fills the vacant spots on the source
island with new offspring or randomly generated individuals [6]. The number of
individuals moved at every migration interval is called the &ldquo;migration size.&rdquo;
The reader can refer to [8, 9] for more information on how the migration
interval and the migration size affect the performance of an island model.</p>
<p>The island model offers a means of faster convergence since each island can
potentially follow a different evolutionary trajectory covering different parts
of the search space. Furthermore, exchanging individuals between islands can
help the overall optimization process avoid being stuck in some local
minimum/maximum. That doesn&rsquo;t mean that the island model is impervious to local
extrema.</p>
<h2 id="when-should-we-use-gas">When should we use GAs?</h2>
<p>As we have seen, GAs can optimize virtually any function given
a well-defined cost function (and that&rsquo;s the most challenging part of using
GAs). However, there are some cases where we should try to use a GA
instead of any other conventional optimization method. These instances are:</p>
<ol>
<li>If the search space is massive, then GAs are suitable for optimizing a
function in that space (for instance, non-linear functions).</li>
<li>Another issue with Optimization is the cost function. The cost function may
be discontinuous (having gaps), or it may be non-differentiable. GAs do not
use derivatives and are therefore immune to such issues.</li>
<li>When a cost function is too complex, GAs have more chances than the vanilla
optimization methods to avoid local minima and correctly find the global
optimum. A genetic algorithm can simultaneously explore the search space in
multiple directions, even if some offspring will never discover an optimal
solution to the problem.</li>
<li>Finally, GAs are agnostic to the problem at hand. They do not require any
information about the system or the function they optimize to solve the
optimization problem.</li>
</ol>
<h2 id="what-are-some-of-the-gas-applications">What are some of the GAs applications?</h2>
<p>Here, you can find some of the GA&rsquo;s applications in real life. Although the
the following list is not complete; you will glimpse where and how GAs are used.</p>
<ol>
<li><strong>Optimization</strong> As discussed in this post, GAs can optimize almost any function.</li>
<li><strong>Machine learning</strong> GAs can tune ML/DL models to discover optimal neural
network parameters. Moreover, they can design neural networks (searching
for the optimal neural network topology [10]).</li>
<li><strong>Path and trajectory planning</strong> GAs can aid in the designing and planning
of paths and trajectories for autonomous robotic platforms, vehicles, or
manipulators, such as robotic arms.</li>
<li><strong>DNA Analysis</strong> GAs can analyze the structure of DNA samples.</li>
<li><strong>Finance</strong> GAs are an excellent tool for analyzing and forecasting stock prices.</li>
<li><strong>Aerospace engineering</strong> GAs can aid in the process of designing
aircraft.</li>
<li><strong>Traveling salesman problem (TSP)</strong> The
<a href="https://en.wikipedia.org/wiki/Travelling_salesman_problem">TSP</a> is
well-defined in combinatorial Optimization and has many applications in
real-life issues.</li>
</ol>
</div>
<h3 id="cited-as">Cited as:</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-latex" data-lang="latex"><span style="display:flex;"><span>@article{detorakis2022geneticalg,
</span></span><span style="display:flex;"><span>  title   = &#34;Genetic algorithms and island models&#34;,
</span></span><span style="display:flex;"><span>  author  = &#34;Georgios Is. Detorakis&#34;,
</span></span><span style="display:flex;"><span>  journal = &#34;gdetor.github.io&#34;,
</span></span><span style="display:flex;"><span>  year    = &#34;2022&#34;,
</span></span><span style="display:flex;"><span>  url     = &#34;https://gdetor.github.io/posts/genetics_algorithms&#34;
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><h3 id="references">References</h3>
<ol>
<li>D. A. Pierre, <em>Optimization theory with applications</em>, Courier Corporation, 1986.</li>
<li>I. Goodfellow, B. Yoshua, and A. Courville, <em>Deep learning</em>, MIT press, 2016.</li>
<li>K. De Jong, <em>Evolutionary computation</em>, Wiley Interdisciplinary Reviews: Computational Statistics, 2009, 1.1: 52-56.</li>
<li>G. Is. Detorakis and A. Burton, <em>GAIM: A C++ library for Genetic Algorithms and Island Models</em>, Journal of Open Source Software, 2019, 4.44: 1839.</li>
<li>D. Whitley, S. Rana, and R.B. Heckendorn, <em>The island model genetic algorithm: On separability, population size and convergence</em>, Journal of computing and information technology, 7:1, 33&ndash;47, 1999.</li>
<li>D. Sudholt, <em>Parallel evolutionary algorithms</em>, Springer Handbook of Computational Intelligence, 929&ndash;959, 2015.</li>
<li>W. N. Martin, J. Lienig, and J. P. Cohoon, <em>Parallel Genetic Algorithms Based on Punctuated Equilibria</em>, Handbook of Evolutionary Computation, IOP Publishing group, 1997.</li>
<li>Z. Skolicki, <em>An analysis of island models in evolutionary computation</em>, Proceedings of the 7th annual workshop on Genetic and evolutionary computation, 386&ndash;389, 2005.</li>
<li>Z. Skolicki, and K. De Jong, <em>The influence of migration sizes and intervals on island models</em>, Proceedings of the 7th annual conference on genetic and evolutionary computation, 1295&ndash;1302, 2005.</li>
<li>K. O. Stanley, and R. Miikkulainen, <em>Efficient evolution of neural network topologies</em>, Proceedings of the 2002 Congress on Evolutionary Computation. 2, 1757&ndash;1762, 2002.</li>
</ol>
</section>

  <footer class="mt-12 flex flex-wrap"><a
      class="mb-1.5 rounded-lg bg-black/[3%] px-5 py-1 no-underline hover:bg-black/[6%] ltr:mr-1.5 rtl:ml-1.5 dark:bg-white/[8%] dark:hover:bg-white/[12%]"
      href="https://gdetor.github.io/tags/genetic-algorithms"
      >genetic algorithms</a
    ><a
      class="mb-1.5 rounded-lg bg-black/[3%] px-5 py-1 no-underline hover:bg-black/[6%] ltr:mr-1.5 rtl:ml-1.5 dark:bg-white/[8%] dark:hover:bg-white/[12%]"
      href="https://gdetor.github.io/tags/gaim"
      >GAIM</a
    ><a
      class="mb-1.5 rounded-lg bg-black/[3%] px-5 py-1 no-underline hover:bg-black/[6%] ltr:mr-1.5 rtl:ml-1.5 dark:bg-white/[8%] dark:hover:bg-white/[12%]"
      href="https://gdetor.github.io/tags/island-model"
      >island model</a
    ><a
      class="mb-1.5 rounded-lg bg-black/[3%] px-5 py-1 no-underline hover:bg-black/[6%] ltr:mr-1.5 rtl:ml-1.5 dark:bg-white/[8%] dark:hover:bg-white/[12%]"
      href="https://gdetor.github.io/tags/optimization"
      >optimization</a
    ></footer><nav
    class="mt-24 flex overflow-hidden rounded-xl bg-black/[3%] text-lg leading-[1.2]! *:flex *:w-1/2 *:items-center *:p-5 *:font-medium *:no-underline dark:bg-white/[8%] [&>*:hover]:bg-black/[2%] dark:[&>*:hover]:bg-white/[3%]"
  ><a class="ltr:pr-3 rtl:pl-3" href="https://gdetor.github.io/posts/som/"
      ><span class="ltr:mr-1.5 rtl:ml-1.5"></span><span>An introduction to self-organizing maps</span></a
    ><a
      class="justify-end pl-3 ltr:ml-auto rtl:mr-auto"
      href="https://gdetor.github.io/posts/acf_pacf/"
      ><span>Autocorrelation Functions for Time Series</span><span class="ltr:ml-1.5 rtl:mr-1.5"></span></a
    ></nav></article></main><footer
  class="mx-auto flex h-[4.5rem] max-w-(--w) items-center px-8 text-xs tracking-wider uppercase opacity-60"
>
  <div class="mr-auto">Copyright  2024, Georgios Is. Detorakis.</div>
  <a class="link mx-6" href="https://gohugo.io/" rel="noopener" target="_blank"
    >powered by hugo</a
  >
  <a
    class="link"
    href="https://github.com/nanxiaobei/hugo-paper"
    rel="noopener"
    target="_blank"
    >hugo-paper</a
  >
</footer>
</body>
</html>
