<!doctype html>









































<html
  class="not-ready lg:text-base"
  style="--bg: #faf8f1"
  lang="en-us"
>
  <head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta
    name="viewport"
    content="width=device-width, initial-scale=1, shrink-to-fit=no"
  />

  
  <title>Time series forecasting error metrics - GID</title>

  
  <meta name="theme-color" />

  
  
  
  
  <meta name="description" content="In this post, we will explore the basic error measures used in time-series forecasting. Error measures provide a way to quantify the quality of a forecasting algorithm (e.g., the performance). First, we briefly introduce time series and the fundamental terms of forecasting. Second, we will introduce the most commonly used error measures and give examples. Finally, we provide a complete example of using errors in a real-life forecasting scenario.
What is a time series A time series is a series of data points indexed in time order in layman&rsquo;s terms [1, 2]." />
  <meta name="author" content="Georgios Is. Detorakis" />
  

  
  
  
  
  
  
  <link rel="preload stylesheet" as="style" href="https://gdetor.github.io/main.min.css" />

  
  
  
  
  
  <link rel="preload" as="image" href="https://gdetor.github.io/theme.png" />

  
  
  
  
  <link rel="preload" as="image" href="https://avatars.githubusercontent.com/u/7115299?v=4" />
  
  

  
  
  <link rel="preload" as="image" href="https://gdetor.github.io/github.svg" />
  
  <link rel="preload" as="image" href="https://gdetor.github.io/linkedin.svg" />
  
  

  
  
  <script
    defer
    src="https://gdetor.github.io/highlight.min.js"
    onload="hljs.initHighlightingOnLoad();"
  ></script>
  

  
  
  
  <link
  rel="stylesheet"
  href="https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/katex.min.css"
  integrity="sha384-3UiQGuEI4TTMaFmGIZumfRPtfKQ3trwQE2JgosJxCnGmQpL/lJdjpcHkaaFwHlcI"
  crossorigin="anonymous"
/>
<script
  defer
  src="https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/katex.min.js"
  integrity="sha384-G0zcxDFp5LWZtDuRMnBkk3EphCK1lhEf4UEyEM693ka574TZGwo4IWwS6QLzM/2t"
  crossorigin="anonymous"
></script>
<script
  defer
  src="https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/contrib/auto-render.min.js"
  integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05"
  crossorigin="anonymous"
></script>

<script>
  document.addEventListener('DOMContentLoaded', () =>
    renderMathInElement(document.body, {
      
      
      delimiters: [
        { left: '$$', right: '$$', display: true },
        { left: '$', right: '$', display: false },
      ],
      
      throwOnError: false,
    }),
  );
</script>

  
  
  

  
  <link rel="icon" href="https://gdetor.github.io/icons/favicon.ico" />
  <link rel="apple-touch-icon" href="https://gdetor.github.io/apple-touch-icon.png" />

  <link rel="stylesheet" href="/css/highlight.css" />
  
  
  
  
 
  
  <meta name="generator" content="Hugo 0.92.2" />

  
  
  
  
  
  <meta itemprop="name" content="Time series forecasting error metrics">
<meta itemprop="description" content="Error measures provide a way to quantify the quality of a forecasting algorithm (*e.g.*, performance). We briefly introduce time series and the fundamental terms of forecasting. We will then introduce the most commonly used error measures and give some examples. We provide an example of how to use error metrics in a real-life forecasting scenario."><meta itemprop="datePublished" content="2022-05-05T00:00:00+00:00" />
<meta itemprop="dateModified" content="2022-05-05T00:00:00+00:00" />
<meta itemprop="wordCount" content="2944">
<meta itemprop="keywords" content="mean squared error,MSE,MAE,mean absolute error,time series,R2,coefficient of determination," />
  
  <meta property="og:title" content="Time series forecasting error metrics" />
<meta property="og:description" content="Error measures provide a way to quantify the quality of a forecasting algorithm (*e.g.*, performance). We briefly introduce time series and the fundamental terms of forecasting. We will then introduce the most commonly used error measures and give some examples. We provide an example of how to use error metrics in a real-life forecasting scenario." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://gdetor.github.io/posts/errors/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-05-05T00:00:00+00:00" />
<meta property="article:modified_time" content="2022-05-05T00:00:00+00:00" />


  
  <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Time series forecasting error metrics"/>
<meta name="twitter:description" content="Error measures provide a way to quantify the quality of a forecasting algorithm (*e.g.*, performance). We briefly introduce time series and the fundamental terms of forecasting. We will then introduce the most commonly used error measures and give some examples. We provide an example of how to use error metrics in a real-life forecasting scenario."/>

  
  
  
  <link rel="canonical" href="https://gdetor.github.io/posts/errors/" />
  
  
</head>

  <body class="text-black duration-200 ease-out dark:text-white">
    
    
    <script src="/js/copybutton.js"></script>
    

    <header class="mx-auto flex h-[4.5rem] max-w-3xl px-8 lg:justify-center">
  <div class="relative z-50 mr-auto flex items-center">
    <a
      class="-translate-x-[1px] -translate-y-[1px] text-2xl font-semibold"
      href="https://gdetor.github.io"
      >GID</a
    >
    <div
      class="btn-dark text-[0] ml-4 h-6 w-6 shrink-0 cursor-pointer [background:url(./theme.png)_left_center/_auto_theme('spacing.6')_no-repeat] [transition:_background-position_0.4s_steps(5)] dark:[background-position:right]"
      role="button"
      aria-label="Dark"
    ></div>
  </div>

  <div
    class="btn-menu relative z-50 -mr-8 flex h-[4.5rem] w-[5rem] shrink-0 cursor-pointer flex-col items-center justify-center gap-2.5 lg:hidden"
    role="button"
    aria-label="Menu"
  ></div>

  

  <script>
    
    const htmlClass = document.documentElement.classList;
    setTimeout(() => {
      htmlClass.remove('not-ready');
    }, 10);

    
    const btnMenu = document.querySelector('.btn-menu');
    btnMenu.addEventListener('click', () => {
      htmlClass.toggle('open');
    });

    
    const metaTheme = document.querySelector('meta[name="theme-color"]');
    const lightBg = '#faf8f1'.replace(/"/g, '');
    const setDark = (isDark) => {
      metaTheme.setAttribute('content', isDark ? '#000' : lightBg);
      htmlClass[isDark ? 'add' : 'remove']('dark');
      localStorage.setItem('dark', isDark);
    };

    
    const darkScheme = window.matchMedia('(prefers-color-scheme: dark)');
    if (htmlClass.contains('dark')) {
      setDark(true);
    } else {
      const darkVal = localStorage.getItem('dark');
      setDark(darkVal ? darkVal === 'true' : darkScheme.matches);
    }

    
    darkScheme.addEventListener('change', (event) => {
      setDark(event.matches);
    });

    
    const btnDark = document.querySelector('.btn-dark');
    btnDark.addEventListener('click', () => {
      setDark(localStorage.getItem('dark') !== 'true');
    });
  </script>

  <div
    class="nav-wrapper fixed inset-x-0 top-full z-40 flex h-full select-none flex-col justify-center pb-16 duration-200 dark:bg-black lg:static lg:h-auto lg:flex-row lg:!bg-transparent lg:pb-0 lg:transition-none"
  >
    
    
    <nav class="lg:ml-12 lg:flex lg:flex-row lg:items-center lg:space-x-6">
      
      <a
        class="block text-center text-2xl leading-[5rem] lg:text-base lg:font-normal"
        href="/about/"
        >About</a
      >
      
      <a
        class="block text-center text-2xl leading-[5rem] lg:text-base lg:font-normal"
        href="/research/"
        >Research</a
      >
      
      <a
        class="block text-center text-2xl leading-[5rem] lg:text-base lg:font-normal"
        href="/software/"
        >Software</a
      >
      
      <a
        class="block text-center text-2xl leading-[5rem] lg:text-base lg:font-normal"
        href="/publications/"
        >Publications</a
      >
      
      <a
        class="block text-center text-2xl leading-[5rem] lg:text-base lg:font-normal"
        href="/artwork/"
        >Artwork</a
      >
      
    </nav>
    

    
    <nav
      class="mt-12 flex justify-center space-x-10 dark:invert lg:ml-12 lg:mt-0 lg:items-center lg:space-x-6"
    >
      
      <a
        class="h-8 w-8 text-[0] [background:var(--url)_center_center/cover_no-repeat] lg:h-6 lg:w-6"
        style="--url: url(./github.svg)"
        href="https://github.com/gdetor"
        target="_blank"
        rel="me"
      >
        github
      </a>
      
      <a
        class="h-8 w-8 text-[0] [background:var(--url)_center_center/cover_no-repeat] lg:h-6 lg:w-6"
        style="--url: url(./linkedin.svg)"
        href="https://linkedin.com/in/georgiosdetorakis"
        target="_blank"
        rel="me"
      >
        linkedin
      </a>
      
    </nav>
    
  </div>
</header>


    <main
      class="prose prose-neutral relative mx-auto min-h-[calc(100%-9rem)] max-w-3xl px-8 pb-16 pt-12 dark:prose-invert"
    >
      

<article>
  <header class="mb-16">
    <h1 class="!my-0 pb-2.5">Time series forecasting error metrics</h1>

    
    <div class="text-sm antialiased opacity-60">
      
      <time>May 5, 2022</time>
      
      
      
      
      <span class="mx-1">&middot;</span>
      <span>Georgios Is. Detorakis</span>
      <span class="mx-1">&middot;</span>
      <span class="inline-item reading">14 minutes read</span>
      
    </div>
    
  </header>

  <section><div style="text-align: justify;">
<p>In this post, we will explore the basic error measures
used in time-series forecasting. Error measures provide a way
to quantify the quality of a forecasting algorithm (<em>e.g.</em>, the
performance). First, we briefly introduce time series and the
fundamental terms of forecasting. Second, we will introduce the
most commonly used error measures and give examples. Finally,
we provide a complete example of using errors in a real-life
forecasting scenario.</p>
<h2 id="what-is-a-time-series">What is a time series</h2>
<p>A time series is a series of data points indexed in time order in
layman&rsquo;s terms [1, 2].
A few examples of time series are</p>
<ul>
<li>The daily closing price of a stock in the stock market</li>
<li>The number of air passengers per month</li>
<li>The biosignals recorded from electroencephalogram or electrocardiogram</li>
</ul>
<p>Figure 1 shows the number of air passengers per month from January 1949
to September 1960. You can download the data from Kaggle
<a href="https://www.kaggle.com/datasets/rakannimer/air-passengers">here</a>.</p>
<figure><img src="/images/passengers.png"
         alt="Figure 1. An example of a time series showing the number of air passengers per month."/><figcaption>
            <p>Figure 1. An example of a time series showing the number of air passengers per month.</p>
        </figcaption>
</figure>
<p>A more rigorous definition of a time series found in [1] (Chapter 1, pg 1)
is given below:</p>
<p>Let $ k \in \mathbf{N}, T \subseteq \mathbf{R} $. A function
$$ x: T \rightarrow \mathbf{R}^k, \hspace{2mm} t \rightarrow x_t $$
or equivalently, a set of indexed elements of $ \mathbf{R}^k $,
$$  { x_t | x_t \in \mathbf{R}^k, \hspace{2mm} t \in T }  $$
is called an observed time series (or time series).
Sometimes, we write $ x_t(t \in T) $ or $ (x_t)_{t\in T} $.</p>
<p>When $ k = 1 $ the time series is called <em>univariate</em>, otherwise is
called <em>multivariate</em>.
$ T $ determines if the time series is [1]:</p>
<ul>
<li><strong>discrete</strong> $ T $ is countable, and $ \forall a &lt; b \in \mathbb{R}: T \cap[a, b] $
is finite,</li>
<li><strong>continuous</strong> $ T = [a, b], a &lt; b \in \mathbb{R}, T = \mathbb{R}_{+}
\hspace{2mm} \text{or} \hspace{2mm} T = \mathbb{R} $,</li>
<li><strong>equidistant</strong> $ T $ is discrete, and $ \exists u \hspace{2mm} s.t. \hspace{2mm} t_{j+1} - t_j = u $.</li>
</ul>
<blockquote>
<p>From now on and for simplicity&rsquo;s sake we will use the following notation for
a time series: $ y[1], y[2], \ldots , y[N] $, where
$ N \in \mathbb{N} $ or $ y[t] $, where $t=1, \ldots , N $.</p>
</blockquote>
<h2 id="more-terminology">More terminology</h2>
<p>Before we dive into the post, let&rsquo;s give some valuable terminology for the
unfamiliar reader.</p>
<ul>
<li><strong>Observed data</strong> ($ (y_t)_{t\in T} $ or $ y[t] $) This is the
data we obtain by observing a system or a process.</li>
<li><strong>Predictive model</strong> Is a mathematical representation of observed data.</li>
<li><strong>Target</strong> ($ y[t] $) This is the ground truth signal we use to train
a predictor.</li>
<li><strong>Horizon</strong> ($ h $) Is the number of points or steps we predict in
the future.</li>
<li><strong>Prediction</strong> ($ \hat{y}[t] = y[t+h] $) This is a value that predictor
returns.</li>
<li><strong>Forecasting</strong> Is the process of predicting future values from historical
and present data.</li>
<li><strong>Outlier</strong> This value significantly differs from other time series values.</li>
<li><strong>Error</strong> ($ \epsilon[t] $) is the difference between the target signal
and the prediction of our model. The error is given by
$ \epsilon[t] = y[t] - \hat{y}[t] $.</li>
<li><strong>Seasonality</strong> ($ S $) Seasonality is the periodic appearance of specific
patterns over the same period—for instance, increasing prices before and
over the Christmas holidays.</li>
</ul>
<h2 id="four-basic-predictors">Four basic predictors</h2>
<p>So far, we have seen what a time series is and the basic terminology.
Now, we will explore some essential predictors or models and see how to use them to forecast.</p>
<p>As we&rsquo;ve already seen, a predictor is a statistical (or mathematical)
model that receives as input historical and present data and returns one
(one-step ahead forecasting, $ h = 1$) or multiple future values
(multi-step ahead prediction, $ h &gt; 1 $).
The development of predictors is out of the scope of this post, so we
will not see how to build, train, test/validate, and use a predictor (here
are a few references where the reader can find more details on that matter
[3, 4, 5, 6]). However, we will introduce the four elementary
predictors since some error measures use some of them to estimate the
prediction errors.</p>
<h4 id="naive-predictor">Naive predictor</h4>
<p>The most straightforward predictor we can imagine is the <em>naive</em> one. It takes
the last observed value and returns it as the predicted value:</p>
<p>$$ \hat{y}[t + h | t] = y[t]. $$</p>
<h4 id="seasonal-predictor">Seasonal predictor</h4>
<p>We can use the seasonal predictor when we know that our time series
has a seasonal component (seasonality). It is a natural extension of
the naive one, and we can describe it as:</p>
<p>$$ \hat{y}[t+h|t] = y[t+h-S(P+1)]. $$</p>
<p>$ P $ is $ \Big[\frac{h-1}{S}\Big] $, where $ \Big[ x \Big] $ is the
integer part of $ x $. $ P $ reflects the number of years&ndash;365 days&ndash;
have passed prior to time $ t + h $.</p>
<h4 id="average-predictor">Average predictor</h4>
<p>This predictor receives historical and present values as input,
computes their average (or mean), and returns it as a prediction:</p>
<p>$$ \hat{y}[t+h|t] = \bar{y} = \frac{1}{N} \sum_{t=1}^{N} y[t] .$$</p>
<h4 id="drift-predictor">Drift predictor</h4>
<p>Another variation of the naive predictor, only this time
we allow to the predicted value to <em>drift</em> (fluctuate) over time,</p>
<p>$$ \hat{y}[t+h|t] = y[t] + \frac{h}{t-1} \sum_{j=2}^{t} (y[j]-y[j-1]) = y[t] + h\Big( \frac{y[t] - y[1]}{t - 1} \Big). $$</p>
<p>You can picture this predictor as a line drawn from the first
observation to the last one and beyond, where beyond is the prediction.</p>
<p>Figure 2 shows the predictions in each of the cases mentioned above for the air
passenger data (brown line). The blue line represents the naive predictor,
the green line represents the seasonal predictor, the orange line represents
the average predictor, and the pink line indicates the drift predictor.</p>
<figure><img src="/images/naive_predictors.png"
         alt="Figure 2. Forecasts of montly air passengers. Naive predictor (blue line), naive seasonal (green), average (orange), drift (pink)."/><figcaption>
            <p>Figure 2. Forecasts of montly air passengers. Naive predictor (blue line), naive seasonal (green), average (orange), drift (pink).</p>
        </figcaption>
</figure>
<h2 id="forecasting-error-measures">Forecasting error measures</h2>
<p>So why do we need error measures? The general idea is to quantify the distance
between an actual observation (target) and a predicted one. Particularly when
we train a model to learn how to predict future values, we have to measure the
error between the actual and predicted observations.
Hence, minimizing the error leads to a better model.</p>
<p>When we teach a model, we need to use penalties to help it improve its predictions.
The error measures listed below do precisely that. They measure how far the
model’s predictions are from the ground truth and penalize the model accordingly.
Usually, the smaller the error, the better the predictor.</p>
<p>Another reason we need error measures is to evaluate the performance
of our model in real-life scenarios. We might have a trained model
that performs some forecasting, and we would like to investigate the
quality of its predictions. In this case, we can measure the error
between the historical data we will collect in the future and the
model&rsquo;s predictions.</p>
<p>We already said that developing and training a predictor is out of
the scope of the present post. Therefore, we will use historical
data and add Gaussian noise to fake the predictions.
Furthermore, we adopt the discrete-time signals time indexing, meaning
that $ y[t] $ is the time series value at time index $ t $.
A similar way would be $ y_t $, where $ t $ is the time index.</p>
<blockquote>
<p><strong>Reminder</strong> $ y[t] $ is the target signal, $ \hat{y}[t] $ the prediction
signal and $ \epsilon[t] $ the error signal.</p>
</blockquote>
<p>And now, we are ready to introduce the error measures and some examples
demonstrating their behavior.</p>
<h4 id="example">Example</h4>
<p>In the following sections, we use some basic examples to demonstrate how the
reader can implement the error measures in Python. In every case, we provide a
custom implementation of the error measure and a Sklearn one. The reader should
rely more on the Sklearn [7] implementation since it’s generic and optimized.
We provide a custom implementation so the reader can better understand the
mathematical formulas.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np
np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>seed(<span style="color:#ae81ff">13</span>)

y_true <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array([<span style="color:#ae81ff">1.5</span>, <span style="color:#f92672">-</span><span style="color:#ae81ff">0.5</span>, <span style="color:#ae81ff">2.5</span>, <span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">1</span>])        <span style="color:#75715e"># This is y (target)</span>

y_pred <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array([<span style="color:#ae81ff">1</span>, <span style="color:#f92672">-</span><span style="color:#ae81ff">0.3</span>, <span style="color:#ae81ff">2.6</span>, <span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">2.4</span>, <span style="color:#ae81ff">1.2</span>])      <span style="color:#75715e"># This is y_hat (prediction)</span>

</code></pre></div><h3 id="mean-absolute-error-mae">Mean Absolute Error (MAE)</h3>
<p>The MAE is the most straightforward error measure, and as its
name signifies, it is just the difference between a target (or desired)
value and model&rsquo;s prediction. MAE is defined as:</p>
<p>$$ \frac{1}{N} \sum_{t=1}^{N} |y[t] - \hat{y}[t]| = \frac{1}{N} \sum_{t=1}^{N} | \epsilon[t] |. $$</p>
<p>By observing the definition of MAE, we can see that MAE is
scale-dependent, meaning that both signals, target and prediction,
must be of the same scale. Another drawback of MAE that we can identify
by its definition is its sensitivity to outliers (<em>e.g.</em>,
values in the time series that stick further away from any other value).
Outliers can drag the MAE to higher values, thus affecting the error.
However, there are ways to handle outliers and fix that issue (see here [8, 9]).</p>
<h4 id="example-1">Example</h4>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> sklearn.metrics <span style="color:#f92672">import</span> mean_absolute_error

<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">MAE</span>(y_true, y_pred):
    N <span style="color:#f92672">=</span> len(y_true)
    error <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>abs(y_true <span style="color:#f92672">-</span> y_pred)<span style="color:#f92672">.</span>sum()
    <span style="color:#66d9ef">return</span> error <span style="color:#f92672">/</span> N

print(MAE(y, y_hat))
<span style="color:#ae81ff">0.2333333333333333</span>

print(mean_absolute_error(y, y_hat))
<span style="color:#ae81ff">0.2333333333333333</span>
</code></pre></div><h3 id="mean-absolute-percentage-error-mape">Mean Absolute Percentage Error (MAPE)</h3>
<p>MAPE computes the error between a target and a prediction signal
as a ratio of the error $ \epsilon[t] $ and the target signal. More
precisely,</p>
<p>$$ MAPE = \frac{100\%}{N} \sum_{t=1}^{N} \frac{|y[t] - \hat{y}[t]|}{|y[t]|} = \frac{100}{N} \sum_{t=1}^{N} \frac{| \epsilon[t] |}{| y[t] |}. $$</p>
<p>MAPE is a helpful error measure when it serves as a loss function
in training and validating a regression model [10]. This error measure is not
susceptible to global scaling of the target signal.</p>
<p>Again, we can draw some conclusions about this measure by observing the
definition of MAPE above. MAPE can be problematic when the actual values are
zero or near zero. We can see from the definition above that when the denominator
is close to zero or zero, the MAPE is too large or cannot be defined.
Moreover, MAPE is susceptible to skewness since the term $ \frac{1}{y[t]} $
depends only on the observed data (not on the model&rsquo;s predictions).</p>
<h4 id="example-2">Example</h4>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> sklearn.metrics <span style="color:#f92672">import</span> mean_absolute_percentage_error

<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">MAPE</span>(y_true, y_pred):
    N <span style="color:#f92672">=</span> len(y_true)
    error <span style="color:#f92672">=</span> (np<span style="color:#f92672">.</span>abs(y_true <span style="color:#f92672">-</span> y_pred) <span style="color:#f92672">/</span> np<span style="color:#f92672">.</span>abs(y_true))<span style="color:#f92672">.</span>sum()
    <span style="color:#66d9ef">return</span> (<span style="color:#ae81ff">100.0</span> <span style="color:#f92672">/</span> N) <span style="color:#f92672">*</span> error

print(MAPE(y, y_hat))
<span style="color:#ae81ff">19.5555555555555557</span>                 <span style="color:#75715e"># this is because we multiply by 100</span>
    
print(mean_absolute_percentage_error(y, y_hat))
<span style="color:#ae81ff">0.19555555555555554</span>                 
</code></pre></div><h3 id="mean-squared-error-mse">Mean Squared Error (MSE)</h3>
<p>The MSE is one of the most used error measures in Machine and
Deep learning. It computes the average of the square of the errors
between target and prediction signals. We define the MSE as:</p>
<p>$$ MSE = \frac{1}{N} \sum_{t=1}^{N} (y[t] - \hat{y}[t])^2 = \frac{1}{N} \sum_{t=1}^{N} \epsilon[t]^2 . $$</p>
<p>If we take the square root of $ MSE $, we get the Root MSE or RMSE.
When the MSE is zero, we call the predictor (model) a perfect predictor.
MSE falls into the category of quadratic errors. Quadratic errors
tend to exaggerate the difference between the target and the model&rsquo;s
prediction, rendering them suitable for training models since the
penalty applied to the model will be more prominent when the error
signal is significant [11].</p>
<p>MSE combines the <em>bias</em> and the <em>variance</em> of a prediction. More
precisely, $ MSE = b^2 + Var $, where $b$ is the bias term and
$ Var $ is the variance. The bias reflects the assumptions the
model makes to simplify finding answers. The more
assumptions a model makes, the larger the bias. On the other hand,
variance refers to how the answers given by the model are subject
to change when we present different training/testing data to the
model. Usually, linear models such as <em>Linear Regression</em> and
<em>Logistic Regression</em> has high bias and low variance. Nonlinear
models such as <em>Decision Trees</em>,  <em>SVM</em>, and <em>kNN</em> have low
bias and high variance [12]. Ideally, we would like to find a balance
between bias and variance. That&rsquo;s why sometimes we have to penalize
our model during training using regularization techniques (this is
out of the scope of the present post).</p>
<h4 id="example-3">Example</h4>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> sklearn.metrics <span style="color:#f92672">import</span> mean_squared_error

<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">MSE</span>(y_true, y_pred):
    N <span style="color:#f92672">=</span> len(y_true)
    error <span style="color:#f92672">=</span> ((y_true <span style="color:#f92672">-</span> y_pred)<span style="color:#f92672">**</span><span style="color:#ae81ff">2</span>)<span style="color:#f92672">.</span>sum()
    <span style="color:#66d9ef">return</span> error <span style="color:#f92672">/</span> N

print(MSE(y_true, y_pred))
<span style="color:#ae81ff">0.08333333333333333</span>
    
print(mean_squared_error(y_true, y_pred))
<span style="color:#ae81ff">0.08333333333333333</span>
</code></pre></div><h3 id="symmetric-mean-absolute-percentage-error-smape">Symmetric Mean Absolute Percentage Error (SMAPE)</h3>
<p>SMAPE computes the error between the target and the prediction signals
as a ratio of the error with the sum of the absolute values of actual
and prediction values.
The mathematical definition for SMAPE is:</p>
<p>$$ SMAPE = \frac{100\%}{N} \sum_{t=1}^{N} \frac{| \epsilon [t] |}{(| y[t]| + | \hat{y}[t] |)} $$</p>
<p>And as we can see from that definition, SMAPE is bounded from
above and below, $ 0 \leq SMAPE \leq 100 $. Another remark we
can make based on  SMAPE&rsquo;s definition is that when both a target and
a prediction value are zero, the SMAPE is not defined. If only
the actual or target value is zero, $ SMAPE = 100 $. Finally,
SMAPE can cause troubles when, let&rsquo;s say, a prediction is
$ \hat{y}[t] = 10 $ the first time and $ \hat{y}[t] = 12 $ the
second time, while in both cases, the target (actual) value is
$ y[t] = 11 $.  In the former case, $ SMAPE  = 4.7 % $ and in
the latter case $ SMAPE = 4.3 % $. We see that we get two different
error values for the same target when our predictor returns
different predictions.</p>
<h3 id="mean-absolute-scaled-error-mase">Mean Absolute Scaled Error (MASE)</h3>
<p>MASE is a metric that computes the error ratio between the
target and the model&rsquo;s prediction to a naive predictor&rsquo;s error (forecaster).</p>
<p>The following equation gives the MASE,</p>
<p>$$ MASE = \frac{\frac{1}{N} \sum_{t=1}^{N} | \epsilon[t] | }{\frac{1}{N-1} \sum_{t=2}^{N} | y[t] - y[t-1] | } $$</p>
<p>When we are dealing with time series with seasonality with period
$ S $ we can use the following MASE formula instead:</p>
<p>$$ MASE = \frac{\frac{1}{N} \sum_{t=1}^{N} | \epsilon[t] | }{\frac{1}{N-S} \sum_{t=S+1}^{N} | y[t] - y[t-S] | }. $$</p>
<p>MASE is scale-invariant, meaning that it&rsquo;s immune to any scaling
we perform on the observed data. MASE is symmetric, which implies
that it penalizes both positive and negative (as well
as big and small) forecast errors equally. When the MASE error exceeds
one, the naive forecaster performs better than our model. MASE can
only be problematic when the actual (target) signal has zero values.
In that case, the naive predictor will be zero ad infinitum; thus,
the MASE will be undefined.</p>
<h3 id="coefficient-of-determination-cod-or-r">Coefficient of Determination (CoD) or R²</h3>
<p>The $ R^2 $ or Coefficient of Determination is an error measure
frequently used in evaluating regression models (<em>goodness of fit</em>
or <em>best-fit line</em>). $ R^2 $ counts how many of the target data
points approach the line formed by the regression [11].</p>
<p>We define $ R^2 $ as</p>
<p>$$ R^2 = 1 - \frac{\sum_{t=1}^{N}(y[t] - \hat{y}[t])^2 }{\sum_{t=1}^{N}(y[t] - \bar{y})^2} = 1 - \frac{MSE}{Var[y[t]]}, $$</p>
<p>or alternatively</p>
<p>$$ R^2 = \frac{SSR}{SST} = \frac{\sum_{t=1}^{N}(y[t] - \hat{y}[t])^2 }{\sum_{t=1}^{N}(y[t] - \bar{y})^2}. $$</p>
<p>SSR is the sum of squares regression, and SST is the sum of squares
total. SSR represents the total variation of all the predicted values
found on the regression plane from the mean value of all the values
of response variables. SST reflects the total variation of actual
values (targets) from the mean value of all the values of response
variables.</p>
<p>$R^2$ is bounded from above, $R^2 \leq 1$, since the fraction term
lives always in the interval $ [0, 1] $. In the case of training, a
regression model $ R^2 $ is bounded from bellow $ 0 \leq R^2 \leq 1 $.
For the test/validation data, $ R^2 $ can be negative when MSE is
large, or the total variance of the target (actual) signal is too
small. A negative $ R^2 $ implies that the term $ \bar{y} $ is a
better predictor than our model. Moreover, from the first definition
of $ R^2 $, we see a direct relation between $ R^2 $ and MSE. While
the $ R^2 $ increases, the MSE tends to approach zero. When we have
an ideal predictor, $ MSE = 0 $ and $ r^2 = 1 $.</p>
<h4 id="example-4">Example</h4>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> sklearn.metrics <span style="color:#f92672">import</span> r2_score
<span style="color:#f92672">from</span> numpy <span style="color:#f92672">import</span> var

<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">R2</span>(y_true, y_pred):
    mse <span style="color:#f92672">=</span> MSE(y_true, y_pred)
    variance <span style="color:#f92672">=</span> var(y_true)
    <span style="color:#66d9ef">return</span> <span style="color:#ae81ff">1.0</span> <span style="color:#f92672">-</span> (mse <span style="color:#f92672">/</span> var)

print(R2(y_true, y_pred))
<span style="color:#ae81ff">0.9351351351351351</span>
    
print(r2_score(y_true, y_pred))
<span style="color:#ae81ff">0.9351351351351351</span>
</code></pre></div><h2 id="summary">Summary</h2>
<p>In this post, we briefly introduced the concept of time series and the most frequently used error measures in forecasting. We described the pros and cons of each measure so the reader can decide which one best suits their needs. If you find any typos or errors, or you have any other comments, please feel free to report them (you can find contact information <a href="/about">here</a>).</p>
</div>
<h3 id="cited-as">Cited as:</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-latex" data-lang="latex">@article{detorakis2022errors-timeseries,
  title   = &#34;Time series and forecasting error measures&#34;,
  author  = &#34;Georgios Is. Detorakis&#34;,
  journal = &#34;gdetor.github.io&#34;,
  year    = &#34;2022&#34;,
  url     = &#34;https://gdetor.github.io/posts/errors&#34;
}
</code></pre></div><h3 id="references">References</h3>
<ol>
<li>J. Beran, <em>Mathematical Foundations of Time Series Analysis A Concise
Introduction</em>, Springer, 2017.</li>
<li><a href="https://en.wikipedia.org/wiki/Time_series">&ldquo;Time series&rdquo;</a>, Wikipedia,
Wikimedia Foundation, May 2 2022.</li>
<li>A. Nielsen, <em>Practical time series analysis: Prediction with statistics
and machine learning</em>, O&rsquo;Reilly Media, 2019.</li>
<li>R. J. Hyndman, and G. Athanasopoulos, <em>Forecasting: principles and practice</em>,
OTexts, 2018.</li>
<li>D. Oliveira, <em>Deep learning for time series forecasting</em>,
<a href="https://www.kaggle.com/code/dimitreoliveira/deep-learning-for-time-series-forecasting">https://www.kaggle.com/code/dimitreoliveira/deep-learning-for-time-series-forecasting</a>,
Kaggle, 2019.</li>
<li>R. Mulla, <em>[Tutorial] TIme series forecasting with XGBoost</em>,
<a href="https://www.kaggle.com/code/robikscube/tutorial-time-series-forecasting-with-xgboost">https://www.kaggle.com/code/robikscube/tutorial-time-series-forecasting-with-xgboost</a>,
Kaggle, 2019.</li>
<li>Pedregosa, F. et al., <em>Scikit-learn: Machine Learning in Python</em>,
Journal of Machine Learning Research, 12, 2825&ndash;2830, 2011.</li>
<li>F. Grubbs, <em>Sample Criteria for Testing Outlying Observations</em>,
Annals of Mathematical Statistics 21(1):27–58, DOI:10.1214/aoms/1177729885, 1950.</li>
<li>B. Rosner, <em>Percentage Points for a Generalized ESD Many-Outlier Procedure</em>,
Technometrics 25(2):165–172, 1983.</li>
<li>A. de Myttenaere, B. Golden, B. Le Grand, and F. Rossi, <em>Mean absolute percentage
error for regression models</em>, Neurocomputing, 2016.</li>
<li>A. Kumar, <em>Mean squared error or R-squared - Which one to use?</em>
<a href="https://vitalflux.com/mean-square-error-r-squared-which-one-to-use/">https://vitalflux.com/mean-square-error-r-squared-which-one-to-use/</a>, 2022.</li>
<li>C. M. Bishop, and N. M. Nasrabadi, <em>Pattern recognition and machine learning</em>,
New York: Springer, 2006.</li>
</ol>
</section>

  
  
  <footer class="mt-12 flex flex-wrap">
     
    <a
      class="mb-1.5 mr-1.5 rounded-lg bg-black/[3%] px-5 py-1.5 no-underline dark:bg-white/[8%]"
      href="https://gdetor.github.io/tags/mean-squared-error"
      >mean squared error</a
    >
     
    <a
      class="mb-1.5 mr-1.5 rounded-lg bg-black/[3%] px-5 py-1.5 no-underline dark:bg-white/[8%]"
      href="https://gdetor.github.io/tags/mse"
      >MSE</a
    >
     
    <a
      class="mb-1.5 mr-1.5 rounded-lg bg-black/[3%] px-5 py-1.5 no-underline dark:bg-white/[8%]"
      href="https://gdetor.github.io/tags/mae"
      >MAE</a
    >
     
    <a
      class="mb-1.5 mr-1.5 rounded-lg bg-black/[3%] px-5 py-1.5 no-underline dark:bg-white/[8%]"
      href="https://gdetor.github.io/tags/mean-absolute-error"
      >mean absolute error</a
    >
     
    <a
      class="mb-1.5 mr-1.5 rounded-lg bg-black/[3%] px-5 py-1.5 no-underline dark:bg-white/[8%]"
      href="https://gdetor.github.io/tags/time-series"
      >time series</a
    >
     
    <a
      class="mb-1.5 mr-1.5 rounded-lg bg-black/[3%] px-5 py-1.5 no-underline dark:bg-white/[8%]"
      href="https://gdetor.github.io/tags/r2"
      >R2</a
    >
     
    <a
      class="mb-1.5 mr-1.5 rounded-lg bg-black/[3%] px-5 py-1.5 no-underline dark:bg-white/[8%]"
      href="https://gdetor.github.io/tags/coefficient-of-determination"
      >coefficient of determination</a
    >
    
  </footer>
  

  
  
  
  
  <nav class="mt-24 flex rounded-lg bg-black/[3%] text-lg dark:bg-white/[8%]">
    
    <a
      class="flex w-1/2 items-center rounded-l-md p-6 pr-3 font-semibold no-underline hover:bg-black/[2%] dark:hover:bg-white/[3%]"
      href="https://gdetor.github.io/posts/normalization/"
      ><span class="mr-1.5">←</span><span>Useful data transformations</span></a
    >
    
    
    <a
      class="ml-auto flex w-1/2 items-center justify-end rounded-r-md p-6 pl-3 font-semibold no-underline hover:bg-black/[2%] dark:hover:bg-white/[3%]"
      href="https://gdetor.github.io/posts/genetic_algorithms/"
      ><span>Genetic Algorithms &amp; Island Models</span><span class="ml-1.5">→</span></a
    >
    
  </nav>
  
  

  
  

  
  

  


  
</article>


    </main>
	
    <footer
  class="opaco mx-auto flex h-[4.5rem] max-w-3xl items-center px-8 text-[0.9em] opacity-60"
>
  <div class="mr-auto">
    &copy; 2025
    <a class="link" href="https://gdetor.github.io">GID</a>
  </div>
  <a class="link mx-6" href="https://gohugo.io/" rel="noopener" target="_blank"
    >Powered by Hugo️️</a
  >️
  <a
    class="link"
    href="https://github.com/nanxiaobei/hugo-paper"
    rel="noopener"
    target="_blank"
    >✎ Paper</a
  >
</footer>

    
  </body>
</html>
