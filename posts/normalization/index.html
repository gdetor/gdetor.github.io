<!doctype html>









































<html
  class="not-ready lg:text-base"
  style="--bg: #faf8f1"
  lang="en-us"
>
  <head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta
    name="viewport"
    content="width=device-width, initial-scale=1, shrink-to-fit=no"
  />

  
  <title>Useful data transformations - GID</title>

  
  <meta name="theme-color" />

  
  
  
  
  <meta name="description" content="This post briefly introduces fundamental data transformations such as mean subtraction (centering data), normalization, standardization, difference transform, and power transform. Furthermore, we provide simple examples of Python code for applying those transforms to real data. Moreover, we heavily rely on the sklearn Python package [1].
Mean subtraction Let&rsquo;s assume we have some data in a vector $ {\bf x} $, and know that the mean value of $ {\bf x} $ is not zero." />
  <meta name="author" content="Georgios Is. Detorakis" />
  

  
  
  
  
  
  
  <link rel="preload stylesheet" as="style" href="https://gdetor.github.io/main.min.css" />

  
  
  
  
  
  <link rel="preload" as="image" href="https://gdetor.github.io/theme.png" />

  
  
  
  
  <link rel="preload" as="image" href="https://avatars.githubusercontent.com/u/7115299?v=4" />
  
  

  
  
  <link rel="preload" as="image" href="https://gdetor.github.io/github.svg" />
  
  <link rel="preload" as="image" href="https://gdetor.github.io/linkedin.svg" />
  
  

  
  
  <script
    defer
    src="https://gdetor.github.io/highlight.min.js"
    onload="hljs.initHighlightingOnLoad();"
  ></script>
  

  
  
  
  <link
  rel="stylesheet"
  href="https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/katex.min.css"
  integrity="sha384-3UiQGuEI4TTMaFmGIZumfRPtfKQ3trwQE2JgosJxCnGmQpL/lJdjpcHkaaFwHlcI"
  crossorigin="anonymous"
/>
<script
  defer
  src="https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/katex.min.js"
  integrity="sha384-G0zcxDFp5LWZtDuRMnBkk3EphCK1lhEf4UEyEM693ka574TZGwo4IWwS6QLzM/2t"
  crossorigin="anonymous"
></script>
<script
  defer
  src="https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/contrib/auto-render.min.js"
  integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05"
  crossorigin="anonymous"
></script>

<script>
  document.addEventListener('DOMContentLoaded', () =>
    renderMathInElement(document.body, {
      
      
      delimiters: [
        { left: '$$', right: '$$', display: true },
        { left: '$', right: '$', display: false },
      ],
      
      throwOnError: false,
    }),
  );
</script>

  
  
  

  
  <link rel="icon" href="https://gdetor.github.io/icons/favicon.ico" />
  <link rel="apple-touch-icon" href="https://gdetor.github.io/apple-touch-icon.png" />

  <link rel="stylesheet" href="/css/highlight.css" />
  
  
  
  
 
  
  <meta name="generator" content="Hugo 0.92.2" />

  
  
  
  
  
  <meta itemprop="name" content="Useful data transformations">
<meta itemprop="description" content="Fundamental data transformations such as mean subtraction (centering data), normalization, and standardization are standard preprocessing steps for many algorithms. Therefore, in this post, we provide some information regarding different basic data transformations as well as simple examples of Python code for applying those transforms to real data."><meta itemprop="datePublished" content="2022-10-13T00:00:00+00:00" />
<meta itemprop="dateModified" content="2022-10-13T00:00:00+00:00" />
<meta itemprop="wordCount" content="1333">
<meta itemprop="keywords" content="normalization,standardize,scaling,centered,difference transform,power transform," />
  
  <meta property="og:title" content="Useful data transformations" />
<meta property="og:description" content="Fundamental data transformations such as mean subtraction (centering data), normalization, and standardization are standard preprocessing steps for many algorithms. Therefore, in this post, we provide some information regarding different basic data transformations as well as simple examples of Python code for applying those transforms to real data." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://gdetor.github.io/posts/normalization/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-10-13T00:00:00+00:00" />
<meta property="article:modified_time" content="2022-10-13T00:00:00+00:00" />


  
  <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Useful data transformations"/>
<meta name="twitter:description" content="Fundamental data transformations such as mean subtraction (centering data), normalization, and standardization are standard preprocessing steps for many algorithms. Therefore, in this post, we provide some information regarding different basic data transformations as well as simple examples of Python code for applying those transforms to real data."/>

  
  
  
  <link rel="canonical" href="https://gdetor.github.io/posts/normalization/" />
  
  
</head>

  <body class="text-black duration-200 ease-out dark:text-white">
    
    
    <script src="/js/copybutton.js"></script>
    

    <header class="mx-auto flex h-[4.5rem] max-w-3xl px-8 lg:justify-center">
  <div class="relative z-50 mr-auto flex items-center">
    <a
      class="-translate-x-[1px] -translate-y-[1px] text-2xl font-semibold"
      href="https://gdetor.github.io"
      >GID</a
    >
    <div
      class="btn-dark text-[0] ml-4 h-6 w-6 shrink-0 cursor-pointer [background:url(./theme.png)_left_center/_auto_theme('spacing.6')_no-repeat] [transition:_background-position_0.4s_steps(5)] dark:[background-position:right]"
      role="button"
      aria-label="Dark"
    ></div>
  </div>

  <div
    class="btn-menu relative z-50 -mr-8 flex h-[4.5rem] w-[5rem] shrink-0 cursor-pointer flex-col items-center justify-center gap-2.5 lg:hidden"
    role="button"
    aria-label="Menu"
  ></div>

  

  <script>
    
    const htmlClass = document.documentElement.classList;
    setTimeout(() => {
      htmlClass.remove('not-ready');
    }, 10);

    
    const btnMenu = document.querySelector('.btn-menu');
    btnMenu.addEventListener('click', () => {
      htmlClass.toggle('open');
    });

    
    const metaTheme = document.querySelector('meta[name="theme-color"]');
    const lightBg = '#faf8f1'.replace(/"/g, '');
    const setDark = (isDark) => {
      metaTheme.setAttribute('content', isDark ? '#000' : lightBg);
      htmlClass[isDark ? 'add' : 'remove']('dark');
      localStorage.setItem('dark', isDark);
    };

    
    const darkScheme = window.matchMedia('(prefers-color-scheme: dark)');
    if (htmlClass.contains('dark')) {
      setDark(true);
    } else {
      const darkVal = localStorage.getItem('dark');
      setDark(darkVal ? darkVal === 'true' : darkScheme.matches);
    }

    
    darkScheme.addEventListener('change', (event) => {
      setDark(event.matches);
    });

    
    const btnDark = document.querySelector('.btn-dark');
    btnDark.addEventListener('click', () => {
      setDark(localStorage.getItem('dark') !== 'true');
    });
  </script>

  <div
    class="nav-wrapper fixed inset-x-0 top-full z-40 flex h-full select-none flex-col justify-center pb-16 duration-200 dark:bg-black lg:static lg:h-auto lg:flex-row lg:!bg-transparent lg:pb-0 lg:transition-none"
  >
    
    
    <nav class="lg:ml-12 lg:flex lg:flex-row lg:items-center lg:space-x-6">
      
      <a
        class="block text-center text-2xl leading-[5rem] lg:text-base lg:font-normal"
        href="/about/"
        >About</a
      >
      
      <a
        class="block text-center text-2xl leading-[5rem] lg:text-base lg:font-normal"
        href="/research/"
        >Research</a
      >
      
      <a
        class="block text-center text-2xl leading-[5rem] lg:text-base lg:font-normal"
        href="/software/"
        >Software</a
      >
      
      <a
        class="block text-center text-2xl leading-[5rem] lg:text-base lg:font-normal"
        href="/publications/"
        >Publications</a
      >
      
      <a
        class="block text-center text-2xl leading-[5rem] lg:text-base lg:font-normal"
        href="/artwork/"
        >Artwork</a
      >
      
    </nav>
    

    
    <nav
      class="mt-12 flex justify-center space-x-10 dark:invert lg:ml-12 lg:mt-0 lg:items-center lg:space-x-6"
    >
      
      <a
        class="h-8 w-8 text-[0] [background:var(--url)_center_center/cover_no-repeat] lg:h-6 lg:w-6"
        style="--url: url(./github.svg)"
        href="https://github.com/gdetor"
        target="_blank"
        rel="me"
      >
        github
      </a>
      
      <a
        class="h-8 w-8 text-[0] [background:var(--url)_center_center/cover_no-repeat] lg:h-6 lg:w-6"
        style="--url: url(./linkedin.svg)"
        href="https://linkedin.com/in/georgiosdetorakis"
        target="_blank"
        rel="me"
      >
        linkedin
      </a>
      
    </nav>
    
  </div>
</header>


    <main
      class="prose prose-neutral relative mx-auto min-h-[calc(100%-9rem)] max-w-3xl px-8 pb-16 pt-12 dark:prose-invert"
    >
      

<article>
  <header class="mb-16">
    <h1 class="!my-0 pb-2.5">Useful data transformations</h1>

    
    <div class="text-sm antialiased opacity-60">
      
      <time>Oct 13, 2022</time>
      
      
      
      
      <span class="mx-1">&middot;</span>
      <span>Georgios Is. Detorakis</span>
      <span class="mx-1">&middot;</span>
      <span class="inline-item reading">7 minutes read</span>
      
    </div>
    
  </header>

  <section><div style="text-align: justify;">
<p>This post briefly introduces fundamental data transformations such as mean
subtraction (centering data), normalization, standardization, difference
transform, and power transform. Furthermore, we provide simple examples of
Python code for applying those transforms to real data. Moreover, we heavily
rely on the <em>sklearn</em> Python package [1].</p>
<h2 id="mean-subtraction">Mean subtraction</h2>
<p>Let&rsquo;s assume we have some data in a vector $ {\bf x} $, and know that the
mean value of $ {\bf x} $ is not zero. We could force the mean to be zero by
subtracting the mean from each element in the vector $ {\bf x} $. Thus, we center
the data when we apply the following transform:</p>
<p>$$ {\bf z} = {\bf x} - \bar{x}, \quad (1) $$</p>
<p>where $ \bar{x} $ is the mean of $ {\bf x} $. Another important use of this
transform is this: When we would like to compare data sets of different scales,
such as temperatures in Celcius and Fahrenheit, we can center each data set
separately and then compare them.</p>
<p>The following code snippet shows how we can center data in Python:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np

X <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>normal(<span style="color:#ae81ff">5</span>, <span style="color:#ae81ff">1</span>, (<span style="color:#ae81ff">100</span>,))
X_bar <span style="color:#f92672">=</span> X<span style="color:#f92672">.</span>mean()
print(X_bar)		<span style="color:#75715e"># 4.9911754</span>

Z <span style="color:#f92672">=</span> X <span style="color:#f92672">-</span> X_bar
print(Z<span style="color:#f92672">.</span>mean()) 	<span style="color:#75715e"># -2.930988e-16 </span>
</code></pre></div><h2 id="normalize">Normalize</h2>
<p>Originally, data normalization meant rescaling and shifting a data set&rsquo;s values
so that they range in $ [0, 1] $. The mathematical formula to do that is:</p>
<p>$$ {\bf z} = \frac{ {\bf x} - x_{\text{min}} }{ x_{\text{max}} - x_{\text{min}} }, \quad (2) $$</p>
<p>where $ {\bf x} $ is the input data, $ x_{\text{min}} $ is the minimum element
in the vector $ {\bf x} $, and $ x_{\text{max}} $ is the maximum element.</p>
<p>However, if we would like to normalize our data into a different interval
$ [a, b] $ we can use the following formula:</p>
<p>$$ {\bf z} = \frac{ {\bf x} - x_{\text{min}} }{ x_{\text{max}} - x_{\text{min}} } (b - a) + a. \quad (3) $$</p>
<p>Normalization is used when we know our data do not follow a Gaussian distribution.</p>
<p>In Python, we can normalize any data set using the <em>MinMaxScaler</em> function
of <em>sklearn</em> [2].</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np
<span style="color:#f92672">from</span> sklearn.preprocessing <span style="color:#f92672">import</span> MinMaxScaler

X <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>random((<span style="color:#ae81ff">100</span>, <span style="color:#ae81ff">1</span>))

<span style="color:#75715e"># Normalize into [0, 1]</span>
scaler <span style="color:#f92672">=</span> MinMaxScaler()
Z <span style="color:#f92672">=</span> scaler<span style="color:#f92672">.</span>fit_transform(X)

<span style="color:#75715e"># Normalize into [2, 4]</span>
scaler <span style="color:#f92672">=</span> MinMaxScaler(feature_range<span style="color:#f92672">=</span>(<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">4</span>))
Z <span style="color:#f92672">=</span> scaler<span style="color:#f92672">.</span>fit_transform(X)

</code></pre></div><h2 id="standarize">Standarize</h2>
<p>Let&rsquo;s assume that we have some data on people&rsquo;s height and weight, and we would
like to use machine learning models on them. Naturally, weight and height
measure different physical quantities and thus are in various scales and units
(height is usually between $ 10 $ and $ 200 $ kilograms, and height is between
$ 0 $ to $ 2 $ m). So, <em>how do we use that data</em>? One solution is to
standardize the data using the z-score</p>
<p>$$  {\bf z} = \frac{{\bf x} - \bar{x}}{\sigma}, \quad (4)  $$</p>
<p>where $ {\bf x} $ is the vector that holds the data, $ \bar{x} $ is the mean
value of $ {\bf x} $, and $ \sigma $ is the standard deviation.
Standardizing our data means they will have a zero mean and a unit standard
deviation. We usually apply a standardization transformation when we know that
our data follow a Gaussian-like distribution.</p>
<p>In Python, we can standardize our data using the preprocessing functions
provided by the <em>sklearn</em> package [3]. Here is an example:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np
<span style="color:#f92672">from</span> sklearn.preprocessing <span style="color:#f92672">import</span> StandardScaler

X <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>empty((<span style="color:#ae81ff">100</span>, <span style="color:#ae81ff">2</span>))
<span style="color:#75715e"># Both weight and height follow a Gaussian distribution</span>
X[:, <span style="color:#ae81ff">0</span>] <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>normal(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">2</span>, (<span style="color:#ae81ff">100</span>, ))		<span style="color:#75715e"># height in meters</span>
X[:, <span style="color:#ae81ff">1</span>] <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>normal(<span style="color:#ae81ff">70</span>, <span style="color:#ae81ff">50</span>, (<span style="color:#ae81ff">100</span>,))		<span style="color:#75715e"># weight in kilograms</span>

scaler <span style="color:#f92672">=</span> StandardScaler()
Z <span style="color:#f92672">=</span> scaler<span style="color:#f92672">.</span>fit_transform(X)
</code></pre></div><p>When we should use a standardization of our data:</p>
<ul>
<li>Before <em>PCA</em>. Sometimes data points with high variance get weighted
more and dominate the principal components.</li>
<li>Before clustering algorithms such as <em>k-means</em>. Clustering algorithms are based
on the notion of distance as a similarity measure; thus, data with a wide
range of features will affect the distances of the clustering algorithm more.</li>
<li>Before <em>SVM</em>. Classic SVM tries to maximize the distance
between two separable hyperplanes and their support vectors. Thus, data with
a wide range of features will affect the distances in a non-desirable way.</li>
<li>Before <em>LASSO</em> or <em>Ridge</em> regression. These algorithms penalize the
magnitude of their coefficients related to each variable, and thus the scale
of each variable will determine the penalty values. Coefficients with high
variance take small values, and thus they will be penalized less.</li>
</ul>
<p>In the following cases, we can skip standardization since these models are
immune to a wide range of features:</p>
<ul>
<li>Logistic regression</li>
<li>Random forests</li>
<li>Decision trees</li>
<li>Gradient boosting</li>
</ul>
<h2 id="difference-transform">Difference transform</h2>
<p>A difference transform is most useful when we are dealing with time series.
If there is a trend in a time series, and we would like to eliminate it,
we can apply a difference transform by subtracting the value at time $ t-1 $
from the current time $ t $ value. More precisely,</p>
<p>$$ x[t] = x[t] - x[t-1], \quad (5) $$</p>
<p>and if we would like to get rid of a seasonal structure, then we only need
to take into account the period (or frequency) of that seasonality,</p>
<p>$$ x[t] = x[t] - x[t - d], \quad (6) $$</p>
<p>where $ d $ is the delay or the period of seasonality (<em>e.g.</em>, how many
data points in the past we should subtract).</p>
<p>The difference transform is easy to implement in Python. The following code
snippet provides two functions to apply and reverse the difference transform.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np


<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">difference</span>(X, delay<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>):
	n <span style="color:#f92672">=</span> len(X)
    diff <span style="color:#f92672">=</span> [X[i] <span style="color:#f92672">-</span> X[i <span style="color:#f92672">-</span> delay] <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(delay, n)]


<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">invDifference</span>(X, dX, delay<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>):
	n <span style="color:#f92672">=</span> len(X)
    inv <span style="color:#f92672">=</span> [dX[i <span style="color:#f92672">-</span> delay] <span style="color:#f92672">+</span> X[i <span style="color:#f92672">-</span> delay] <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(delay, n)]


<span style="color:#66d9ef">if</span> __name__ <span style="color:#f92672">==</span> <span style="color:#e6db74">&#39;__main__&#39;</span>:
    x <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array([i <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">10</span>)])
    print(x)					<span style="color:#75715e"># 1, 2, 3, 4, 5, 6, 7, 8, 9</span>

    x_diff <span style="color:#f92672">=</span> difference(x, <span style="color:#ae81ff">1</span>)
    print(x_diff)				<span style="color:#75715e"># [1, 1, 1, 1, 1, 1, 1, 1]</span>

	<span style="color:#75715e"># We can obtain similar results when delay=1 using Numpy&#39;s diff function</span>
    x_diff_prime <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>diff(x)
    print(x_diff_prime)			<span style="color:#75715e"># [1 1 1 1 1 1 1 1]</span>

	x_diff_inv <span style="color:#f92672">=</span> invDifference(x, x_diff, <span style="color:#ae81ff">1</span>)
    print(x_diff_inv)			<span style="color:#75715e"># [2, 3, 4, 5, 6, 7, 8, 9]</span>

	<span style="color:#75715e"># Another way to inverse the difference when delay=1 is the following</span>
    x_diff_prime_inv <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>r_[x[<span style="color:#ae81ff">0</span>], x_diff_prime]<span style="color:#f92672">.</span>cumsum()
    print(x_diff_prime_inv)		<span style="color:#75715e"># [1 2 3 4 5 6 7 8 9]</span>
</code></pre></div><h2 id="power-transform">Power transform</h2>
<p>We can apply a power transform to make our data look more ``normal''
(Gaussian-like) and stabilize its variance. There are two major power transforms:
the Cox-Box [4] and the Yeo-Johnson [5]. The <em>sklearn</em> Python package supports
both Cox-Box and Yeo-Johnson transforms. The Box-Cox transform requires strictly
positive data, while the Yeo-Johnson transform supports both positive and negative
data [6].
The following code snippet demonstrates how we can apply them to our data.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np
<span style="color:#f92672">from</span> sklearn.preprocessing <span style="color:#f92672">import</span> PowerTransformer

X <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>random(<span style="color:#ae81ff">10</span>)
print(X)	

<span style="color:#75715e"># array([0.92222554, 0.92306673, 0.82856923, 0.8713333 , 0.08001814,</span>
<span style="color:#75715e">#        0.12258023, 0.5008433 , 0.60396389, 0.24539718, 0.55259061])</span>

pt <span style="color:#f92672">=</span> PowerTransformer(method<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;box-cox&#34;</span>)		<span style="color:#75715e"># or method=&#39;yeo-johnson&#39; (default)</span>

<span style="color:#75715e"># fit_transform receives ndarray of shape (n_samples, n_features)</span>
Z <span style="color:#f92672">=</span> pt<span style="color:#f92672">.</span>fit_transform(X<span style="color:#f92672">.</span>reshape(<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>)	
Z <span style="color:#f92672">=</span> Z[:, <span style="color:#ae81ff">0</span>]								<span style="color:#75715e"># we have only one feature</span>
print(Z)

<span style="color:#75715e"># [-1.71002627  1.17246013 -1.55389497  0.91312675 -0.02584321  0.19532181</span>
<span style="color:#75715e">#  -0.08403872  1.48983064  0.03445026 -0.43138641]</span>
</code></pre></div><h2 id="summary">Summary</h2>
<p>We examined five essential data transforms: centering data,
normalization, standardization, difference, and power transform. We briefly
described the math behind those transformations and provided some Python
functions based on <em>sklearn</em> that implement those transformations.</p>
</div>
<h3 id="cited-as">Cited as</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-latex" data-lang="latex">@article{detorakis2022acfpacf,
  title   = &#34;Useful data transformations&#34;,
  author  = &#34;Georgios Is. Detorakis&#34;,
  journal = &#34;gdetor.github.io&#34;,
  year    = &#34;2022&#34;,
  url     = &#34;https://gdetor.github.io/posts/normalization&#34;
}
</code></pre></div><h3 id="references">References</h3>
<ol>
<li>Pedregosa et al., <em>Scikit-learn: Machine Learning in Python,</em>, JMLR 12, pp. 2825-2830, 2011.</li>
<li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler">Sklearn MinMaxScaler</a></li>
<li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html">Sklearn StandardScaler</a></li>
<li>G. E. Box and D. R. Cox, <em>An analysis of transformations</em>, Journal of the Royal Statistical Society, Series B. 26 (2): 211–252, 1964.</li>
<li>In-Kwon Yeo and R.A. Johnson, <em>A New Family of Power Transformations to Improve Normality or Symmetry</em>, Biometrica, 87(4), 2000.</li>
<li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PowerTransformer.html#sklearn.preprocessing.PowerTransformer">Sklearn PowerTransformer</a></li>
</ol>
</section>

  
  
  <footer class="mt-12 flex flex-wrap">
     
    <a
      class="mb-1.5 mr-1.5 rounded-lg bg-black/[3%] px-5 py-1.5 no-underline dark:bg-white/[8%]"
      href="https://gdetor.github.io/tags/normalization"
      >normalization</a
    >
     
    <a
      class="mb-1.5 mr-1.5 rounded-lg bg-black/[3%] px-5 py-1.5 no-underline dark:bg-white/[8%]"
      href="https://gdetor.github.io/tags/standardize"
      >standardize</a
    >
     
    <a
      class="mb-1.5 mr-1.5 rounded-lg bg-black/[3%] px-5 py-1.5 no-underline dark:bg-white/[8%]"
      href="https://gdetor.github.io/tags/scaling"
      >scaling</a
    >
     
    <a
      class="mb-1.5 mr-1.5 rounded-lg bg-black/[3%] px-5 py-1.5 no-underline dark:bg-white/[8%]"
      href="https://gdetor.github.io/tags/centered"
      >centered</a
    >
     
    <a
      class="mb-1.5 mr-1.5 rounded-lg bg-black/[3%] px-5 py-1.5 no-underline dark:bg-white/[8%]"
      href="https://gdetor.github.io/tags/difference-transform"
      >difference transform</a
    >
     
    <a
      class="mb-1.5 mr-1.5 rounded-lg bg-black/[3%] px-5 py-1.5 no-underline dark:bg-white/[8%]"
      href="https://gdetor.github.io/tags/power-transform"
      >power transform</a
    >
    
  </footer>
  

  
  
  
  
  <nav class="mt-24 flex rounded-lg bg-black/[3%] text-lg dark:bg-white/[8%]">
    
    <a
      class="flex w-1/2 items-center rounded-l-md p-6 pr-3 font-semibold no-underline hover:bg-black/[2%] dark:hover:bg-white/[3%]"
      href="https://gdetor.github.io/posts/acf_pacf/"
      ><span class="mr-1.5">←</span><span>Autocorrelation Functions for Time Series</span></a
    >
    
    
    <a
      class="ml-auto flex w-1/2 items-center justify-end rounded-r-md p-6 pl-3 font-semibold no-underline hover:bg-black/[2%] dark:hover:bg-white/[3%]"
      href="https://gdetor.github.io/posts/errors/"
      ><span>Time series forecasting error metrics</span><span class="ml-1.5">→</span></a
    >
    
  </nav>
  
  

  
  

  
  

  


  
</article>


    </main>
	
    <footer
  class="opaco mx-auto flex h-[4.5rem] max-w-3xl items-center px-8 text-[0.9em] opacity-60"
>
  <div class="mr-auto">
    &copy; 2025
    <a class="link" href="https://gdetor.github.io">GID</a>
  </div>
  <a class="link mx-6" href="https://gohugo.io/" rel="noopener" target="_blank"
    >Powered by Hugo️️</a
  >️
  <a
    class="link"
    href="https://github.com/nanxiaobei/hugo-paper"
    rel="noopener"
    target="_blank"
    >✎ Paper</a
  >
</footer>

    
  </body>
</html>
